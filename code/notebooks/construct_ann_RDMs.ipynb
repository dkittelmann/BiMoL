{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import scipy.io\n",
    "from scipy.spatial.distance import cosine\n",
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ HELPER FUNCTIONS ################################ \n",
    "\n",
    "# create condlist\n",
    "conditionlist = {\n",
    "    'leading_Barn': 0,\n",
    "    'leading_beach': 1,\n",
    "    'leading_library': 2,\n",
    "    'leading_restaurant': 3, \n",
    "    'leading_cave': 4,\n",
    "    'trailing_church': 5,\n",
    "    'trailing_conference_room': 6,\n",
    "    'trailing_castle': 7, \n",
    "    'trailing_forest': 8      \n",
    "}\n",
    "\n",
    "#Create category dict based on conditionlist\n",
    "\n",
    "    #Idea: we create a customised event_id dict that allows us to later just extract \n",
    "    # the trailing images corresponding to our transitional probabiliy categories\n",
    "\n",
    "    # Mapping VALID CONDITIONS (75%): \n",
    "        # leading_barn -> trailing_church\n",
    "        # leading_beach -> trailing_church\n",
    "        # leading_library -> trailing_conference_room\n",
    "        # leading_restaurant ->  trailing_conference_room\n",
    "\n",
    "    # Mapping INVALID CONDITIONS (25%): \n",
    "        # leading_barn -> trailing_conference_room\n",
    "        # leading_beach -> trailing_conference_room\n",
    "        # leading_library -> trailing_church\n",
    "        # leading_restaurant -> trailing_church\n",
    "        \n",
    "    # Mapping CONTROL CONDITIONS (50%): \n",
    "        # leading_cave -> trailing_castle\n",
    "        # leading_cave -> trailing_forest\n",
    "    \n",
    "category_dict = {\n",
    "    0: (0, 5), # valid conditions 75 %\n",
    "    1: (1, 5), # leading_beach -> trailing_church\n",
    "    2: (2, 6), # leading_library -> trailing_conference_room\n",
    "    3: (3, 6),  # leading_restaurant ->  trailing_conference_room\n",
    "    4: (0, 6), # invalid conditions 0.25 %\n",
    "    5: (1, 6),\n",
    "    6: (2, 5), \n",
    "    7: (3, 5), \n",
    "    8: (4, 7), # control conditions 50 %\n",
    "    9: (4, 8)\n",
    "}\n",
    "\n",
    "\n",
    "# Draw batch of images for testing\n",
    "\n",
    "'''def batch_drawing_function(category_dict):\n",
    "  # add the drwaing according to the mapping\n",
    "  # 35 leading\n",
    "  # 45 trailing '''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define resultspath\n",
    "results_path_pcn = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/rdms/ann_RDM/pcn/\"\n",
    "results_path_bp = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/rdms/ann_RDM/backprop/\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dict that assigns the correct labels for each leading-trailing imgage pair\n",
    "\n",
    "\"\"\"\n",
    "L1 = barn = label 0 - cat 1\n",
    "L2 = beach = label 1 - cat 2\n",
    "L5 = cave = label 2 - cat 3\n",
    "L3 = library = label - cat 4\n",
    "L4 = restaurant = label 4 - cat 5\n",
    "\n",
    "\n",
    "L1 = barn = label 0 \n",
    "L2 = beach = label 1\n",
    "L3 = cave = label 2\n",
    "L4 = library = label 3\n",
    "L5 = restaurant = label 4 \n",
    "\n",
    "    % Map 1 = C1 LEADING >> C6 TRAILING valid, C7 invalid\n",
    "    % Map 2 = C2 LEADING >> C6 TRAILING valid, C7 invalid\n",
    "    % Map 3 = C4 LEADING >> C7 TRAILING valid, C6 invalid\n",
    "    % Map 4 = C5 LEADING >> C7 TRAILING valid, C6 invalid\n",
    "    % Map 5 = C3 LEADING >> C8 OR C9 TRAILING\n",
    "    % Map 6 = C3 LEADING >> C9 OR C9 TRAILING\n",
    "\n",
    "\n",
    "T6 = Church = label 1   \n",
    "T7 = conference room = label 2\n",
    "T8 = castle = label 0   \n",
    "T9 = forest = label 3\n",
    "\n",
    "MAPPING:\n",
    "\n",
    "L1 -> T6 = 0.75 -> (0,1) \n",
    "L1 -> T7 = 0.25 -> (0,2)\n",
    "L1 -> T8 = 0 -> (0,0)\n",
    "L1 -> T9 = 0 -> (0,3)\n",
    "\n",
    "L2 -> T6 = 0.75 -> (1,1) \n",
    "L2 -> T7 = 0.25 -> (1,2)\n",
    "L2 -> T8 = 0 -> (1,0)\n",
    "L2 -> T9 = 0 -> (1,3)\n",
    "\n",
    "L3 -> T6 = 0 -> (3,1) \n",
    "L3 -> T7 = 0 -> (3,2)\n",
    "L3 -> T8 = 0.5 -> (3,0)\n",
    "L3 -> T9 = 0.5 -> (3,3)\n",
    "\n",
    "L4 -> T6 = 0.25 -> (4,1) \n",
    "L4 -> T7 = 0.75 -> (4,2)\n",
    "L4 -> T8 = 0 -> (4,0)\n",
    "L4 -> T9 = 0 -> (4,3)\n",
    "\n",
    "L5 -> T6 = 0.25 -> (2,1) \n",
    "L5 -> T7 = 0.75 -> (2,2)\n",
    "L5 -> T8 = 0 -> (2,0)\n",
    "L5 -> T9 = 0 -> (2,3)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "label_dict = {\n",
    "    (0, 1): 0.0,\n",
    "    (0, 2): 0.75,\n",
    "    (0, 0): 0.25,\n",
    "    (0, 3): 0.25,\n",
    "    \n",
    "    (1, 1): 0.0,\n",
    "    (1, 2): 0.75,\n",
    "    (1, 0): 0.25,\n",
    "    (1, 3): 0.25,\n",
    "    \n",
    "    (3, 1): 0.75,\n",
    "    (3, 2): 0.75,\n",
    "    (3, 0): 0.50,\n",
    "    (3, 3): 0.50,\n",
    "    \n",
    "    (4, 1): 0.75,\n",
    "    (4, 2): 0.0,\n",
    "    (4, 0): 0.25,\n",
    "    (4, 3): 0.25,\n",
    "    \n",
    "    (2, 1): 0.75, \n",
    "    (2, 2): 0.0,\n",
    "    (2, 0): 0.25,\n",
    "    (2, 3): 0.25\n",
    "}\n",
    "\n",
    "\n",
    "# Mapping VALID CONDITIONS (75%): \n",
    "    # leading_barn -> trailing_church\n",
    "    # leading_beach -> trailing_church\n",
    "    # leading_library -> trailing_conference_room\n",
    "    # leading_restaurant ->  trailing_conference_room\n",
    "\n",
    "# Mapping INVALID CONDITIONS (25%): \n",
    "    # leading_barn -> trailing_conference_room\n",
    "    # leading_beach -> trailing_conference_room\n",
    "    # leading_library -> trailing_church\n",
    "    # leading_restaurant -> trailing_church\n",
    "    \n",
    "# Mapping CONTROL CONDITIONS (50%): \n",
    "    # leading_cave -> trailing_castle\n",
    "    # leading_cave -> trailing_forest\n",
    "\n",
    "L1 = barn = label 0 \n",
    "L2 = beach = label 1\n",
    "L3 = cave = label 2\n",
    "L4 = library = label 3\n",
    "L5 = restaurant = label 4 \n",
    "\n",
    "0 -> 1\n",
    "1 -> 1\n",
    "3 -> 2\n",
    "4 -> 2\n",
    "\n",
    "0 -> 2 \n",
    "1 -> 2\n",
    "3 -> 1\n",
    "4 -> 1\n",
    "\n",
    "2 -> 0 \n",
    "2 -> 3 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "T6 = Church = label 1   \n",
    "T7 = conference room = label 2\n",
    "T8 = castle = label 0   \n",
    "T9 = forest = label 3\n",
    "\n",
    "\n",
    "category_dict = {\n",
    "    0: (0, 1), # valid conditions 75 %\n",
    "    1: (1, 1), # leading_beach -> trailing_church\n",
    "    2: (3, 2), # leading_library -> trailing_conference_room\n",
    "    3: (4, 2),  # leading_restaurant ->  trailing_conference_room\n",
    "    4: (0, 2), # invalid conditions 0.25 %\n",
    "    5: (1, 2),\n",
    "    6: (3, 1), \n",
    "    7: (4, 1), \n",
    "    8: (2, 0), # control conditions 50 %\n",
    "    9: (2, 3)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image paths \n",
    "\n",
    "img_dir_lead = '/Users/denisekittelmann/Documents/Python/BiMoL/data/Leading/'\n",
    "img_dir_trail = '/Users/denisekittelmann/Documents/Python/BiMoL/data/Trailing/'\n",
    "img_dir_test_lead = '/Users/denisekittelmann/Documents/Python/BiMoL/data/Test/Test_Leading/'\n",
    "img_dir_test_trail = '/Users/denisekittelmann/Documents/Python/BiMoL/data/Test/Test_Trailing/'\n",
    "class_names_L = ['barn', 'beach', 'cave', 'library', 'restaurant']\n",
    "class_names_T = ['castle', 'Church', 'conference_room', 'forest'] # changed the order \n",
    "batch_size = None # adjust if needed, e.g., 32\n",
    "image_size = (28,28)\n",
    "validation_split = 0.1\n",
    "seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_scale_imgs(imgs, scale_factor):\n",
    "    return imgs * scale_factor + 0.5 * (1 - scale_factor) * tf.ones(imgs.shape)\n",
    "\n",
    "\n",
    "def tf_scale_labels(labels, scale_factor):\n",
    "    return labels * scale_factor + 0.5 * (1 - scale_factor) * tf.ones(labels.shape)\n",
    "\n",
    "\n",
    "def tf_f_inv(x, act_fn):\n",
    "    \"\"\" (activation_size, batch_size) \"\"\"\n",
    "    if act_fn == \"LINEAR\":\n",
    "        m = x\n",
    "    elif act_fn == \"TANH\":\n",
    "        num = tf.ones_like(x) + x\n",
    "        div = tf.ones_like(x) - x + 1e-7\n",
    "        m = 0.5 * tf.math.log(num / div)\n",
    "    elif act_fn == \"LOGSIG\":\n",
    "        div = tf.ones_like(x) - x + 1e-7\n",
    "        m = tf.math.log((x / div) + 1e-7)\n",
    "    else:\n",
    "        raise ValueError(f\"{act_fn} not supported\")\n",
    "    return m\n",
    "\n",
    "\n",
    "def img_preproc(x, y, dtype=tf.float32): \n",
    "  \"\"\"Cast input image to a certain tf dtype and normalize them between 0 and 1.\"\"\"\n",
    "  x = tf.cast(x, dtype) / 255.\n",
    "  #x = tf_scale_imgs(x, cf.img_scale)\n",
    "  #y = tf_scale_labels(y, cf.label_scale)\n",
    "  #x = tf_f_inv(x, \"TANH\")\n",
    "  #y = tf.one_hot(y, depth=10)\n",
    "  return x, y\n",
    "\n",
    "\n",
    "def flatten(x, y):  \n",
    "  #flattens a video image series (or batch of images) to (n_batch, n_steps, 1) d.\n",
    "  shape = tf.shape(x)\n",
    "  if len(shape) == 5: # hack, determining if it's a video or not (batch_size, n_steps, height, width, channels)\n",
    "    x = tf.reshape(x, [shape[0], shape[1], -1])\n",
    "  elif len(shape) == 4: # regular image (batch_size, height, width, channels)\n",
    "    x = tf.reshape(x, [shape[0], -1])\n",
    "  elif len(shape) == 3:  # Single image (height, width, channels)\n",
    "    x = tf.reshape(x, [-1])\n",
    "  return x, y\n",
    "\n",
    "def augment_images(batch_images, batch_labels):\n",
    "    \"\"\"\n",
    "    Applies data augmentation on a batch of images without TensorFlow Addons.\n",
    "    \n",
    "    Parameters:\n",
    "    batch_images: Tensor of shape (n_batch, 56, 28, 3)\n",
    "    \n",
    "    Returns:\n",
    "    Augmented batch of images.\n",
    "    \"\"\"\n",
    "    # Random horizontal flip\n",
    "    augmented_images = tf.image.random_flip_left_right(batch_images)\n",
    "    \n",
    "    # Random brightness adjustment\n",
    "    augmented_images = tf.image.random_brightness(augmented_images, max_delta=0.1)\n",
    "    \n",
    "    # Random contrast adjustment\n",
    "    augmented_images = tf.image.random_contrast(augmented_images, lower=0.9, upper=1.1)\n",
    "    \n",
    "    # Random saturation adjustment\n",
    "    augmented_images = tf.image.random_saturation(augmented_images, lower=0.9, upper=1.1)\n",
    "    \n",
    "    # Random hue adjustment\n",
    "    augmented_images = tf.image.random_hue(augmented_images, max_delta=0.05)\n",
    "    \n",
    "    # Clipping to ensure pixel values are valid after transformations\n",
    "    augmented_images = tf.clip_by_value(augmented_images, 0.0, 1.0)\n",
    "    \n",
    "    return augmented_images, batch_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate image pairs \n",
    "def img_sequence(img_t1, img_t2, label_t1, label_t2, label_dict): \n",
    "    \"\"\"This function stacks two images to construct an image pair and assigns a single label based on the label dictionary.\"\"\"\n",
    "    \n",
    "    img_t1 = tf.cast(img_t1, dtype=tf.float32)\n",
    "    img_t2 = tf.cast(img_t2, dtype=tf.float32)\n",
    "    \n",
    "    x = tf.concat([img_t1, img_t2], axis=0) \n",
    "\n",
    "    key_t1 = int(label_t1.numpy())\n",
    "    key_t2 = int(label_t2.numpy())\n",
    " \n",
    "    \n",
    "    if (key_t1, key_t2) in label_dict:\n",
    "        label = label_dict[(key_t1, key_t2)]\n",
    "        #print(f\"Label value found: {label}\")\n",
    "    else:\n",
    "        print(f\"Label pair {(key_t1, key_t2)} not found.\")\n",
    "\n",
    "    \n",
    "    y = tf.cast(tf.random.uniform([]) < label, tf.float32)\n",
    "    y = tf.expand_dims(y, axis=0)  \n",
    "    \n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import itertools\n",
    "\n",
    "def generate_all_combinations(img_dirt1, img_dirt2, class_namest1, class_namest2, label_dict, image_size=None, seed=None): \n",
    "    # Load images from both directories without batching\n",
    "    data_t1 = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        img_dirt1, \n",
    "        label_mode='int',\n",
    "        class_names=class_namest1,\n",
    "        batch_size=None,\n",
    "        color_mode='rgb',\n",
    "        image_size=image_size,\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    data_t2 = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        img_dirt2, \n",
    "        label_mode='int',\n",
    "        class_names=class_namest2,\n",
    "        batch_size=None,\n",
    "        color_mode='rgb',\n",
    "        image_size=image_size,\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    # Convert datasets to lists for pairing\n",
    "    data_t1_list = list(data_t1)\n",
    "    data_t2_list = list(data_t2)\n",
    "\n",
    "    # Create all possible combinations\n",
    "    for (img_t1, label_t1), (img_t2, label_t2) in itertools.product(data_t1_list, data_t2_list):\n",
    "        # Generate image pair and label\n",
    "        x, y = img_sequence(img_t1, img_t2, label_t1, label_t2, label_dict)\n",
    "        yield x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(img_dirt1, img_dirt2, class_namest1, class_namest2, label_dict, image_size = None, seed = None, shuffle = False):       \n",
    "    \n",
    "    \n",
    "    data_t1 = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        img_dirt1, \n",
    "        label_mode = 'int',\n",
    "        class_names= class_namest1,\n",
    "        batch_size = None,\n",
    "        color_mode = 'rgb',\n",
    "        image_size = image_size, \n",
    "        #shuffle = True, \n",
    "        seed = seed\n",
    "        )\n",
    "\n",
    "    data_t2 = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        img_dirt2, \n",
    "        label_mode = 'int',\n",
    "        class_names= class_namest2,\n",
    "        batch_size = None,\n",
    "        color_mode = 'rgb', \n",
    "        image_size = image_size, \n",
    "        #shuffle = True, \n",
    "        seed = seed\n",
    "    )\n",
    "    \n",
    "    if shuffle:\n",
    "        data_t1.shuffle(99999, seed = seed*2)\n",
    "        data_t2.shuffle(99999, seed = seed*3)\n",
    "    \n",
    "    # iterate through shuffled leading and trailing datasets\n",
    "    leading = iter(data_t1)\n",
    "    trailing = iter(data_t2) \n",
    "              \n",
    "    while True:\n",
    "        try:\n",
    "            # Retrieve single samples\n",
    "            img_t1, label_t1 = next(leading)\n",
    "            img_t2, label_t2 = next(trailing)\n",
    "\n",
    "            # Generate x, y pairs for single samples\n",
    "            x, y = img_sequence(img_t1, img_t2, label_t1, label_t2, label_dict) \n",
    "            yield x, y\n",
    "            \n",
    "        except StopIteration:\n",
    "            # Break the loop if no more samples\n",
    "            break\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ PCN NETWORK OBJECT ################################ \n",
    "\n",
    "class CustomDense(tf.keras.layers.Dense):\n",
    "    def call(self, inputs):\n",
    "        \"\"\"This works like a dense, except for the activation being called earlier.\"\"\"\n",
    "        # Apply the activation to the input first\n",
    "        activated_input = self.activation(inputs)\n",
    "        # Perform the matrix multiplication and add the bias\n",
    "        output = tf.matmul(activated_input, self.kernel)\n",
    "        if self.use_bias:\n",
    "            output = output + self.bias\n",
    "        return output\n",
    "\n",
    "\n",
    "class PredictiveCodingNetwork(tf.keras.Sequential):\n",
    "    def __init__(self, layers, vars, beta, **kwargs):\n",
    "        \"\"\"Initialize a PredictiveCodingNetwork\"\"\"\n",
    "        super().__init__(layers, **kwargs)\n",
    "        self.vars = tf.convert_to_tensor(vars, dtype=tf.float32)\n",
    "        self.beta = beta\n",
    "\n",
    "    def call_with_states(self, x):\n",
    "        x_list = [x]\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            x_list.append(x)\n",
    "        return x_list\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        x, y = data\n",
    "\n",
    "        # do the stuff we do in train_epochs\n",
    "        outputs, errors = self.infer(x, y)\n",
    "        self.update_params(outputs, errors)\n",
    "\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        pred = self.call(x)\n",
    "        for metric in self.metrics:\n",
    "            metric.update_state(y, pred)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "   \n",
    "    def infer(self, x_batch, y_batch=None, n_iter=50, return_sequence=False):\n",
    "        \"\"\"Note: while model call, call with states and model evaluate take\n",
    "        2D input, train_step and infer take stacked 3D inputs.\"\"\"\n",
    "        if return_sequence:\n",
    "            errors_time = []\n",
    "            states_time = []\n",
    "        errors = [None for _ in range(len(self.layers))]\n",
    "        f_x_arr = [None for _ in range(len(self.layers))]\n",
    "        f_x_deriv_arr = [None for _ in range(len(self.layers))]\n",
    "        shape = x_batch.shape\n",
    "        batch_size = shape[0]\n",
    "\n",
    "        for itr in range(n_iter):\n",
    "            # if its the first itr, set x to the current forward call\n",
    "            if itr == 0:\n",
    "                x = self.call_with_states(x_batch)\n",
    "\n",
    "                if y_batch is not None:\n",
    "                  x[-1] = y_batch\n",
    "            else:\n",
    "                # update g and x only for consecutive iterations\n",
    "                for l in range(1, len(self.layers)):\n",
    "                    g = tf.multiply(tf.matmul(errors[l], self.layers[l].kernel, transpose_b=True), f_x_deriv_arr[l])\n",
    "                    x[l] = x[l] + self.beta * (-errors[l-1] + g)\n",
    "\n",
    "            # update f_x etc for every iteration\n",
    "            for l in range(len(self.layers)):\n",
    "                f_x = self.layers[l].activation(x[l])\n",
    "                f_x_deriv_fn = self.get_activation_derivative(self.layers[l].activation)\n",
    "                f_x_deriv = f_x_deriv_fn(x[l])\n",
    "                f_x_arr[l] = f_x\n",
    "                f_x_deriv_arr[l] = f_x_deriv\n",
    "                errors[l] = (x[l + 1] - tf.matmul(f_x, self.layers[l].kernel) - self.layers[l].bias) / self.vars[l]\n",
    "            \n",
    "            if return_sequence:\n",
    "                errors_time.append(errors)\n",
    "                states_time.append(x)\n",
    "\n",
    "        # return what we want to return\n",
    "        if return_sequence:\n",
    "            states_time = [tf.stack(tensors, axis=1) for tensors in zip(*states_time)]\n",
    "            errors_time = [tf.stack(tensors, axis=1) for tensors in zip(*errors_time)]\n",
    "            return states_time, errors_time\n",
    "        else:\n",
    "            return x, errors\n",
    "    \n",
    "    # We need to check if we actually need call here.\n",
    "    # Now, call will give us the result of the network after the first inference step\n",
    "    # If we want to have the results after the last inference step, we would need to change this\n",
    "    #def call(self, inputs, training=False):\n",
    "    #    \"\"\"Call, but time distributed.\"\"\"\n",
    "    #    x, errors = self.infer(inputs, return_sequence=False)\n",
    "    #    return x[-1]\n",
    "\n",
    "    def update_params(self, x, errors):\n",
    "        \"\"\"Update the model parameters.\"\"\"\n",
    "        batch_size = tf.cast(tf.shape(x[0])[0], tf.float32)\n",
    "        gradients = []\n",
    "        for l, layer in enumerate(self.layers):\n",
    "            grad_w = self.vars[-1] * (1 / batch_size) * tf.matmul(tf.transpose(self.layers[l].activation(x[l])), errors[l])\n",
    "            grad_b = self.vars[-1] * (1 / batch_size) * tf.reduce_sum(errors[l], axis=0)\n",
    "            gradients.append((-grad_w, layer.kernel))\n",
    "            gradients.append((-grad_b, layer.bias))\n",
    "        self.optimizer.apply_gradients(gradients)\n",
    "\n",
    "    def get_activation_derivative(self, activation):\n",
    "        \"\"\"Return a function for the derivative of the given activation function.\"\"\"\n",
    "        activation_fn = tf.keras.activations.get(activation)\n",
    "        if activation_fn == tf.keras.activations.linear:\n",
    "            return lambda x: tf.ones_like(x)\n",
    "        elif activation_fn == tf.keras.activations.tanh:\n",
    "            return lambda x: 1 - tf.square(tf.nn.tanh(x))\n",
    "        elif activation_fn == tf.keras.activations.sigmoid:\n",
    "            return lambda x: tf.nn.sigmoid(x) * (1 - tf.nn.sigmoid(x))\n",
    "        else:\n",
    "            raise ValueError(f\"{activation} not supported\")\n",
    "        \n",
    "\n",
    "model = PredictiveCodingNetwork([CustomDense(units=6, activation=\"sigmoid\"),\n",
    "                                 CustomDense(units=4, activation=\"sigmoid\"), \n",
    "                                 CustomDense(units=1, activation=\"sigmoid\")], \n",
    "                                vars=[1, 1, 1], # variances. This is super useless and in the code only the last variance is used\n",
    "                                beta=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_FlatMapDataset element_spec=(TensorSpec(shape=(56, 28, 3), dtype=tf.float32, name=None), TensorSpec(shape=(1,), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "seed = 123\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: generate_dataset(img_dir_test_lead, img_dir_test_trail, class_names_L, class_names_T, label_dict, image_size = (28,28), seed = seed),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(56, 28, 3), dtype=tf.float32),  # shape of x \n",
    "        tf.TensorSpec(shape=(1), dtype=tf.float32)  # shape of y \n",
    "    )\n",
    ") \n",
    "\n",
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820ms/step - accuracy: 0.6722 - loss: 3.9074e-08\n",
      "Test Loss: 3.907416257220575e-08, Test Accuracy: 0.6722221970558167\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Unzip the .keras file to access its internal structure\n",
    "keras_file_path = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/model_checkpoint_pcnoriginal_726_0.67.keras\"\n",
    "unzip_path = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/pcn_tt/\"\n",
    "\n",
    "with zipfile.ZipFile(keras_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(unzip_path)\n",
    "\n",
    "# Step 2: Instantiate your custom model with the correct parameters\n",
    "correct_model = model # PCN loaded after reinitialising the network\n",
    "\n",
    "\n",
    "# Now `correct_model` has the loaded weights\n",
    "correct_model.build([None, 4704])\n",
    "correct_model.load_weights(\"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/pcn_tt/model.weights.h5\")\n",
    "\n",
    "correct_model.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-7, weight_decay=1e-2),\n",
    "    loss=\"categorical_crossentropy\",  # Placeholder loss\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Predict states\n",
    "predictions = correct_model.predict(val_dataset.batch(512).map(img_preproc).map(flatten))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = correct_model.evaluate(val_dataset.batch(512).map(img_preproc).map(flatten))\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/nn/03q5gpsn00zd2frzvtms7bh80000gn/T/ipykernel_35599/3913104978.py\", line 16, in <module>\n",
      "    pcn = tf.keras.models.load_model(\n",
      "  File \"/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/keras/src/saving/saving_api.py\", line 187, in load_model\n",
      "    return saving_lib.load_model(\n",
      "  File \"/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/keras/src/saving/saving_lib.py\", line 365, in load_model\n",
      "    return _load_model_from_fileobj(\n",
      "  File \"/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/keras/src/saving/saving_lib.py\", line 442, in _load_model_from_fileobj\n",
      "    model = _model_from_config(\n",
      "  File \"/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/keras/src/saving/saving_lib.py\", line 431, in _model_from_config\n",
      "    model = deserialize_keras_object(\n",
      "  File \"/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/keras/src/saving/serialization_lib.py\", line 718, in deserialize_keras_object\n",
      "    instance = cls.from_config(inner_config)\n",
      "  File \"/Users/denisekittelmann/Documents/Python/BiMoL/code/util/custom_pcn_dense.py\", line 46, in from_config\n",
      "KeyError: 'vars'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "################################ LOAD ANNs ################################ \n",
    "\n",
    "# In find_bestmodel.py we identified the best models for both networks: \n",
    "    # PCN: model at epoch 726 -> 75% \n",
    "    # Backprop_ann: model at epoch 649 -> 75% \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "dir_pcn = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/updated_model_checkpoint.keras\" #\"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/model_checkpoint_pcnoriginal_726_0.67.keras\"\n",
    "dir_bpann = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/bp_ann/model_checkpoint_649_0.67.keras\"\n",
    "\n",
    "# Load the models\n",
    "#pcn = tf.keras.models.load_model(dir_pcn, custom_objects={\"CustomDense\": CustomDense, \"PredictiveCodingNetwork\": PredictiveCodingNetwork})\n",
    "bp_ann = tf.keras.models.load_model(dir_bpann)\n",
    "\n",
    "\n",
    "\n",
    "pcn = tf.keras.models.load_model(\n",
    "    dir_pcn,\n",
    "    custom_objects={\n",
    "        \"CustomDense\": CustomDense,\n",
    "        \"PredictiveCodingNetwork\": PredictiveCodingNetwork\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TrackedList' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Save to a new file\u001b[39;00m\n\u001b[1;32m      8\u001b[0m updated_dir_pcn \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/updated_model_checkpoint.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdated_dir_pcn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/Python/BiMoL/code/util/custom_pcn_dense.py:39\u001b[0m, in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_config\u001b[39m(\u001b[38;5;28mcls\u001b[39m, config):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28mvars\u001b[39m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(config\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvars\u001b[39m\u001b[38;5;124m\"\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     40\u001b[0m     beta \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;28mvars\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mvars\u001b[39m, beta\u001b[38;5;241m=\u001b[39mbeta, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TrackedList' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "model = PredictiveCodingNetwork(vars=[1, 1, 1], beta=0.1)\n",
    "\n",
    "# Load weights\n",
    "dir_pcn = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/model_checkpoint_pcnoriginal_726_0.67.keras\"\n",
    "model.load_weights(dir_pcn)\n",
    "\n",
    "# Save to a new file\n",
    "updated_dir_pcn = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/updated_model_checkpoint.keras\"\n",
    "model.save(updated_dir_pcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Rebuild the Model Architecture\n",
    "# Replace these with the actual parameters and layers you used originally\n",
    "layers = [CustomDense(...), CustomDense(...)]  # Define your layers as in the original model\n",
    "vars = [...]  # The vars used in the original model\n",
    "beta = 0.5  # Replace with the original beta value\n",
    "\n",
    "# Initialize the PredictiveCodingNetwork with the rebuilt architecture\n",
    "pcn_rebuilt = PredictiveCodingNetwork(layers=layers, vars=vars, beta=beta)\n",
    "\n",
    "# Step 2: Load Weights from the Existing Model File\n",
    "# Specify the path to the original saved model file\n",
    "dir_pcn = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/model_checkpoint_pcnoriginal_726_0.67.keras\"\n",
    "pcn_rebuilt.load_weights(dir_pcn)  # Loads the weights from the saved file\n",
    "\n",
    "# Step 3: Save the Rebuilt Model\n",
    "# Now save it to a new file, which includes the updated `get_config` and `from_config`\n",
    "updated_dir_pcn = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/updated_model_checkpoint.keras\"\n",
    "pcn_rebuilt.save(updated_dir_pcn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ COMPUTE ANN RDMs ################################ \n",
    "\n",
    "# list all layer names\n",
    "for layer in pcn.layers:\n",
    "    print(layer.name)\n",
    "    \n",
    "for layer in bp_ann.layers:\n",
    "    print(layer.name)    \n",
    "    \n",
    "# Extract Layer 1’s output\n",
    "layer1_output = pcn.get_layer('layer_name_1').output # output layer 1\n",
    "layer1_output = bp_ann.get_layer('layer_name_1').output# adapt \n",
    "\n",
    "layer1_model_pcn = Model(inputs=pcn.input, outputs=layer1_output) \n",
    "\n",
    "\n",
    "def batch_drawing_function(valid_cat):\n",
    "  # add the drwaing according to the mapping\n",
    "  # 35 leading\n",
    "  # 45 trailing \n",
    "  \n",
    "\n",
    "rdm_h1_pcn = np.zeros([9, 9])\n",
    "rdm_h1_bp = np.zeros([9, 9])\n",
    "\n",
    "rdm_h23_pcn_l1 = np.zeros([9, 9])\n",
    "rdm_h23_pcn_l2 = np.zeros([9, 9])\n",
    "rdm_h23_bp_l1 = np.zeros([9, 9])\n",
    "rdm_h23_bp_l2 = np.zeros([9, 9])\n",
    "\n",
    "#rdm_h2 = np.zeros([9, 9])\n",
    "#rdm_h3 =np.zeros([9, 9])\n",
    "\n",
    "for category_l in category_dict:\n",
    "  for category_t in category_dict: \n",
    "\n",
    "    batch_i = batch_drawing_function(category_l)\n",
    "    pcn_acts_i = pcn(batch_i)\n",
    "\n",
    "    batch_j = batch_drawing_function(category_t)\n",
    "    pcn_acts_j = pcn(batch_j)\n",
    "    \n",
    "    batch_i = batch_drawing_function(category_l)\n",
    "    bp_acts_i = bp_ann(batch_i)\n",
    "\n",
    "    batch_j = batch_drawing_function(category_t)\n",
    "    bp_acts_j = bp_ann(batch_j)\n",
    "    \n",
    "    \n",
    "    # H1\n",
    "    rdm_h1_pcn[category_l, category_t] = cosine(np.mean(pcn_acts_i[0], axis=0), np.mean(pcn_acts_j[0], axis=0))\n",
    "    rdm_h1_bp[category_l, category_t] = cosine(np.mean(bp_acts_i[1], axis=0), np.mean(bp_acts_j[1], axis=0))\n",
    "    \n",
    "    # H2 &H3\n",
    "    rdm_h23_pcn_l1[category_l, category_t] = cosine(np.mean(np.concatenate([layer for layer in pcn_acts_i], axis=1), axis=0), np.mean(np.concatenate([layer for layer in pcn_acts_j], axis=1), axis=0))\n",
    "    rdm_h23_bp_l1[category_l, category_t] = cosine(np.mean(np.concatenate([layer for layer in bp_acts_i], axis=1), axis=0), np.mean(np.concatenate([layer for layer in bp_acts_j], axis=1), axis=0)) \n",
    "    \n",
    "    rdm_h23_pcn_l2[category_l, category_t] = cosine(np.mean(np.concatenate([layer for layer in pcn_acts_i], axis=1), axis=0), np.mean(np.concatenate([layer for layer in pcn_acts_j], axis=1), axis=0))\n",
    "    rdm_h23_bp_l2[category_l, category_t] = cosine(np.mean(np.concatenate([layer for layer in bp_acts_i], axis=1), axis=0), np.mean(np.concatenate([layer for layer in bp_acts_j], axis=1), axis=0)) \n",
    "    \n",
    "\n",
    "   # Save the RDMs \n",
    "    #np.save(os.path.join(results_path_pcn, \"pcn_rdm_h1.npy\"), rdm_h1_pcn)\n",
    "    #np.save(os.path.join(results_path_pcn, \"pcn_rdm_h23_l1.npy\"), rdm_h23_pcn_l1)\n",
    "    #np.save(os.path.join(results_path_pcn, \"pcn_rdm_h23_l1.npy\"), rdm_h23_pcn_l2)\n",
    "    #np.save(os.path.join(results_path_bp, \"bp_rdm_h1.npy\"), rdm_h1_bp)\n",
    "    #np.save(os.path.join(results_path_bp, \"bp_rdm_h23_l1.npy\"), rdm_h23_bp_l1)\n",
    "    #np.save(os.path.join(results_path_bp, \"bp_rdm_h23_l2.npy\"), rdm_h23_bp_l2)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rdm)\n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BiMo_3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
