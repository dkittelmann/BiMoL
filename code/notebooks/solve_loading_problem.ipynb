{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import scipy.io\n",
    "from scipy.spatial.distance import cosine\n",
    "import zipfile\n",
    "import itertools\n",
    "#import sys\n",
    "#sys.path.append('/Users/denisekittelmann/Documents/Python/BiMoL/code/util/')\n",
    "#from custom_pcn_dense import CustomDense, PredictiveCodingNetwork\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_scale_imgs(imgs, scale_factor):\n",
    "    return imgs * scale_factor + 0.5 * (1 - scale_factor) * tf.ones(imgs.shape)\n",
    "\n",
    "\n",
    "def tf_scale_labels(labels, scale_factor):\n",
    "    return labels * scale_factor + 0.5 * (1 - scale_factor) * tf.ones(labels.shape)\n",
    "\n",
    "\n",
    "def tf_f_inv(x, act_fn):\n",
    "    \"\"\" (activation_size, batch_size) \"\"\"\n",
    "    if act_fn == \"LINEAR\":\n",
    "        m = x\n",
    "    elif act_fn == \"TANH\":\n",
    "        num = tf.ones_like(x) + x\n",
    "        div = tf.ones_like(x) - x + 1e-7\n",
    "        m = 0.5 * tf.math.log(num / div)\n",
    "    elif act_fn == \"LOGSIG\":\n",
    "        div = tf.ones_like(x) - x + 1e-7\n",
    "        m = tf.math.log((x / div) + 1e-7)\n",
    "    else:\n",
    "        raise ValueError(f\"{act_fn} not supported\")\n",
    "    return m\n",
    "\n",
    "\n",
    "def img_preproc(x, y, dtype=tf.float32): \n",
    "  \"\"\"Cast input image to a certain tf dtype and normalize them between 0 and 1.\"\"\"\n",
    "  x = tf.cast(x, dtype) / 255.\n",
    "  #x = tf_scale_imgs(x, cf.img_scale)\n",
    "  #y = tf_scale_labels(y, cf.label_scale)\n",
    "  #x = tf_f_inv(x, \"TANH\")\n",
    "  #y = tf.one_hot(y, depth=10)\n",
    "  return x, y\n",
    "\n",
    "\n",
    "def flatten(x, y):  \n",
    "  #flattens a video image series (or batch of images) to (n_batch, n_steps, 1) d.\n",
    "  shape = tf.shape(x)\n",
    "  if len(shape) == 5: # hack, determining if it's a video or not (batch_size, n_steps, height, width, channels)\n",
    "    x = tf.reshape(x, [shape[0], shape[1], -1])\n",
    "  elif len(shape) == 4: # regular image (batch_size, height, width, channels)\n",
    "    x = tf.reshape(x, [shape[0], -1])\n",
    "  return x, y\n",
    "\n",
    "def augment_images(batch_images, batch_labels):\n",
    "    \"\"\"\n",
    "    Applies data augmentation on a batch of images without TensorFlow Addons.\n",
    "    \n",
    "    Parameters:\n",
    "    batch_images: Tensor of shape (n_batch, 56, 28, 3)\n",
    "    \n",
    "    Returns:\n",
    "    Augmented batch of images.\n",
    "    \"\"\"\n",
    "    # Random horizontal flip\n",
    "    augmented_images = tf.image.random_flip_left_right(batch_images)\n",
    "    \n",
    "    # Random brightness adjustment\n",
    "    augmented_images = tf.image.random_brightness(augmented_images, max_delta=0.1)\n",
    "    \n",
    "    # Random contrast adjustment\n",
    "    augmented_images = tf.image.random_contrast(augmented_images, lower=0.9, upper=1.1)\n",
    "    \n",
    "    # Random saturation adjustment\n",
    "    augmented_images = tf.image.random_saturation(augmented_images, lower=0.9, upper=1.1)\n",
    "    \n",
    "    # Random hue adjustment\n",
    "    augmented_images = tf.image.random_hue(augmented_images, max_delta=0.05)\n",
    "    \n",
    "    # Clipping to ensure pixel values are valid after transformations\n",
    "    augmented_images = tf.clip_by_value(augmented_images, 0.0, 1.0)\n",
    "    \n",
    "    return augmented_images, batch_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDense(tf.keras.layers.Dense):\n",
    "    def call(self, inputs):\n",
    "        \"\"\"This works like a dense, except for the activation being called earlier.\"\"\"\n",
    "        # Apply the activation to the input first\n",
    "        activated_input = self.activation(inputs)\n",
    "        # Perform the matrix multiplication and add the bias\n",
    "        output = tf.matmul(activated_input, self.kernel)\n",
    "        if self.use_bias:\n",
    "            output = output + self.bias\n",
    "        return output\n",
    "\n",
    "\n",
    "class PredictiveCodingNetwork(tf.keras.Sequential):\n",
    "    def __init__(self, layers, vars, beta, **kwargs):\n",
    "        \"\"\"Initialize a PredictiveCodingNetwork\"\"\"\n",
    "        super().__init__(layers, **kwargs)\n",
    "        self.vars = tf.convert_to_tensor(vars, dtype=tf.float32)\n",
    "        self.beta = beta\n",
    "\n",
    "    def call_with_states(self, x):\n",
    "        x_list = [x]\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            x_list.append(x)\n",
    "        return x_list\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        x, y = data\n",
    "\n",
    "        # do the stuff we do in train_epochs\n",
    "        outputs, errors = self.infer(x, y)\n",
    "        self.update_params(outputs, errors)\n",
    "\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        pred = self.call(x)\n",
    "        for metric in self.metrics:\n",
    "            metric.update_state(y, pred)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "   \n",
    "    def infer(self, x_batch, y_batch=None, n_iter=50, return_sequence=False):\n",
    "        \"\"\"Note: while model call, call with states and model evaluate take\n",
    "        2D input, train_step and infer take stacked 3D inputs.\"\"\"\n",
    "        if return_sequence:\n",
    "            errors_time = []\n",
    "            states_time = []\n",
    "        errors = [None for _ in range(len(self.layers))]\n",
    "        f_x_arr = [None for _ in range(len(self.layers))]\n",
    "        f_x_deriv_arr = [None for _ in range(len(self.layers))]\n",
    "        shape = x_batch.shape\n",
    "        batch_size = shape[0]\n",
    "\n",
    "        for itr in range(n_iter):\n",
    "            # if its the first itr, set x to the current forward call\n",
    "            if itr == 0:\n",
    "                x = self.call_with_states(x_batch)\n",
    "\n",
    "                if y_batch is not None:\n",
    "                  x[-1] = y_batch\n",
    "            else:\n",
    "                # update g and x only for consecutive iterations\n",
    "                for l in range(1, len(self.layers)):\n",
    "                    g = tf.multiply(tf.matmul(errors[l], self.layers[l].kernel, transpose_b=True), f_x_deriv_arr[l])\n",
    "                    x[l] = x[l] + self.beta * (-errors[l-1] + g)\n",
    "\n",
    "            # update f_x etc for every iteration\n",
    "            for l in range(len(self.layers)):\n",
    "                f_x = self.layers[l].activation(x[l])\n",
    "                f_x_deriv_fn = self.get_activation_derivative(self.layers[l].activation)\n",
    "                f_x_deriv = f_x_deriv_fn(x[l])\n",
    "                f_x_arr[l] = f_x\n",
    "                f_x_deriv_arr[l] = f_x_deriv\n",
    "                errors[l] = (x[l + 1] - tf.matmul(f_x, self.layers[l].kernel) - self.layers[l].bias) / self.vars[l]\n",
    "            \n",
    "            if return_sequence:\n",
    "                errors_time.append(errors)\n",
    "                states_time.append(x)\n",
    "\n",
    "        # return what we want to return\n",
    "        if return_sequence:\n",
    "            states_time = [tf.stack(tensors, axis=1) for tensors in zip(*states_time)]\n",
    "            errors_time = [tf.stack(tensors, axis=1) for tensors in zip(*errors_time)]\n",
    "            return states_time, errors_time\n",
    "        else:\n",
    "            return x, errors\n",
    "    \n",
    "    # We need to check if we actually need call here.\n",
    "    # Now, call will give us the result of the network after the first inference step\n",
    "    # If we want to have the results after the last inference step, we would need to change this\n",
    "    #def call(self, inputs, training=False):\n",
    "    #    \"\"\"Call, but time distributed.\"\"\"\n",
    "    #    x, errors = self.infer(inputs, return_sequence=False)\n",
    "    #    return x[-1]\n",
    "\n",
    "    def update_params(self, x, errors):\n",
    "        \"\"\"Update the model parameters.\"\"\"\n",
    "        batch_size = tf.cast(tf.shape(x[0])[0], tf.float32)\n",
    "        gradients = []\n",
    "        for l, layer in enumerate(self.layers):\n",
    "            grad_w = self.vars[-1] * (1 / batch_size) * tf.matmul(tf.transpose(self.layers[l].activation(x[l])), errors[l])\n",
    "            grad_b = self.vars[-1] * (1 / batch_size) * tf.reduce_sum(errors[l], axis=0)\n",
    "            gradients.append((-grad_w, layer.kernel))\n",
    "            gradients.append((-grad_b, layer.bias))\n",
    "        self.optimizer.apply_gradients(gradients)\n",
    "\n",
    "    def get_activation_derivative(self, activation):\n",
    "        \"\"\"Return a function for the derivative of the given activation function.\"\"\"\n",
    "        activation_fn = tf.keras.activations.get(activation)\n",
    "        if activation_fn == tf.keras.activations.linear:\n",
    "            return lambda x: tf.ones_like(x)\n",
    "        elif activation_fn == tf.keras.activations.tanh:\n",
    "            return lambda x: 1 - tf.square(tf.nn.tanh(x))\n",
    "        elif activation_fn == tf.keras.activations.sigmoid:\n",
    "            return lambda x: tf.nn.sigmoid(x) * (1 - tf.nn.sigmoid(x))\n",
    "        else:\n",
    "            raise ValueError(f\"{activation} not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_dir_lead = '/Users/denisekittelmann/Documents/Python/BiMoL/data/Leading/'\n",
    "img_dir_trail = '/Users/denisekittelmann/Documents/Python/BiMoL/data/Trailing/'\n",
    "img_dir_test_lead = '/Users/denisekittelmann/Documents/Python/BiMoL/data/Test/Test_Leading/'\n",
    "img_dir_test_trail = '/Users/denisekittelmann/Documents/Python/BiMoL/data/Test/Test_Trailing/'\n",
    "class_names_L = ['barn', 'beach', 'cave', 'library', 'restaurant']\n",
    "class_names_T = ['castle', 'Church', 'conference_room', 'forest'] # changed the order \n",
    "batch_size = None # adjust if needed, e.g., 32\n",
    "image_size = (28,28)\n",
    "validation_split = 0.1\n",
    "seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dict that assigns the correct labels for each leading-trailing imgage pair\n",
    "\n",
    "\"\"\"\n",
    "L1 = barn = label 0 - cat 1\n",
    "L2 = beach = label 1 - cat 2\n",
    "L5 = cave = label 2 - cat 3\n",
    "L3 = library = label - cat 4\n",
    "L4 = restaurant = label 4 - cat 5\n",
    "\n",
    "\n",
    "L1 = barn = label 0 \n",
    "L2 = beach = label 1\n",
    "L3 = cave = label 2\n",
    "L4 = library = label 3\n",
    "L5 = restaurant = label 4 \n",
    "\n",
    "    % Map 1 = C1 LEADING >> C6 TRAILING valid, C7 invalid\n",
    "    % Map 2 = C2 LEADING >> C6 TRAILING valid, C7 invalid\n",
    "    % Map 3 = C4 LEADING >> C7 TRAILING valid, C6 invalid\n",
    "    % Map 4 = C5 LEADING >> C7 TRAILING valid, C6 invalid\n",
    "    % Map 5 = C3 LEADING >> C8 OR C9 TRAILING\n",
    "    % Map 6 = C3 LEADING >> C9 OR C9 TRAILING\n",
    "\n",
    "\n",
    "T6 = Church = label 1   \n",
    "T7 = conference room = label 2\n",
    "T8 = castle = label 0   \n",
    "T9 = forest = label 3\n",
    "\n",
    "MAPPING:\n",
    "\n",
    "L1 -> T6 = 0.75 -> (0,1) \n",
    "L1 -> T7 = 0.25 -> (0,2)\n",
    "L1 -> T8 = 0 -> (0,0)\n",
    "L1 -> T9 = 0 -> (0,3)\n",
    "\n",
    "L2 -> T6 = 0.75 -> (1,1) \n",
    "L2 -> T7 = 0.25 -> (1,2)\n",
    "L2 -> T8 = 0 -> (1,0)\n",
    "L2 -> T9 = 0 -> (1,3)\n",
    "\n",
    "L3 -> T6 = 0 -> (3,1) \n",
    "L3 -> T7 = 0 -> (3,2)\n",
    "L3 -> T8 = 0.5 -> (3,0)\n",
    "L3 -> T9 = 0.5 -> (3,3)\n",
    "\n",
    "L4 -> T6 = 0.25 -> (4,1) \n",
    "L4 -> T7 = 0.75 -> (4,2)\n",
    "L4 -> T8 = 0 -> (4,0)\n",
    "L4 -> T9 = 0 -> (4,3)\n",
    "\n",
    "L5 -> T6 = 0.25 -> (2,1) \n",
    "L5 -> T7 = 0.75 -> (2,2)\n",
    "L5 -> T8 = 0 -> (2,0)\n",
    "L5 -> T9 = 0 -> (2,3)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "label_dict = {\n",
    "    (0, 1): 0.0,\n",
    "    (0, 2): 0.75,\n",
    "    (0, 0): 0.25,\n",
    "    (0, 3): 0.25,\n",
    "    \n",
    "    (1, 1): 0.0,\n",
    "    (1, 2): 0.75,\n",
    "    (1, 0): 0.25,\n",
    "    (1, 3): 0.25,\n",
    "    \n",
    "    (3, 1): 0.75,\n",
    "    (3, 2): 0.75,\n",
    "    (3, 0): 0.50,\n",
    "    (3, 3): 0.50,\n",
    "    \n",
    "    (4, 1): 0.75,\n",
    "    (4, 2): 0.0,\n",
    "    (4, 0): 0.25,\n",
    "    (4, 3): 0.25,\n",
    "    \n",
    "    (2, 1): 0.75, \n",
    "    (2, 2): 0.0,\n",
    "    (2, 0): 0.25,\n",
    "    (2, 3): 0.25\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate image pairs \n",
    "def img_sequence(img_t1, img_t2, label_t1, label_t2, label_dict): \n",
    "    \"\"\"This function stacks two images to construct an image pair and assigns a single label based on the label dictionary.\"\"\"\n",
    "    \n",
    "    img_t1 = tf.cast(img_t1, dtype=tf.float32)\n",
    "    img_t2 = tf.cast(img_t2, dtype=tf.float32)\n",
    "    \n",
    "    x = tf.concat([img_t1, img_t2], axis=0) \n",
    "\n",
    "    key_t1 = int(label_t1.numpy())\n",
    "    key_t2 = int(label_t2.numpy())\n",
    " \n",
    "    \n",
    "    if (key_t1, key_t2) in label_dict:\n",
    "        label = label_dict[(key_t1, key_t2)]\n",
    "        #print(f\"Label value found: {label}\")\n",
    "    else:\n",
    "        print(f\"Label pair {(key_t1, key_t2)} not found.\")\n",
    "\n",
    "    \n",
    "    y = tf.cast(tf.random.uniform([]) < label, tf.float32)\n",
    "    y = tf.expand_dims(y, axis=0)  \n",
    "    \n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(img_dirt1, img_dirt2, class_namest1, class_namest2, label_dict, image_size = None, seed = None, shuffle = False):       \n",
    "    \n",
    "    \n",
    "    data_t1 = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        img_dirt1, \n",
    "        label_mode = 'int',\n",
    "        class_names= class_namest1,\n",
    "        batch_size = None,\n",
    "        color_mode = 'rgb',\n",
    "        image_size = image_size, \n",
    "        #shuffle = True, \n",
    "        seed = seed\n",
    "        )\n",
    "\n",
    "    data_t2 = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        img_dirt2, \n",
    "        label_mode = 'int',\n",
    "        class_names= class_namest2,\n",
    "        batch_size = None,\n",
    "        color_mode = 'rgb', \n",
    "        image_size = image_size, \n",
    "        #shuffle = True, \n",
    "        seed = seed\n",
    "    )\n",
    "    \n",
    "    if shuffle:\n",
    "        data_t1.shuffle(99999, seed = seed*2)\n",
    "        data_t2.shuffle(99999, seed = seed*3)\n",
    "    \n",
    "    # iterate through (shuffled) leading and trailing datasets\n",
    "    leading = iter(data_t1)\n",
    "    trailing = iter(data_t2) \n",
    "              \n",
    "    while True:\n",
    "        try:\n",
    "            # Retrieve single samples\n",
    "            img_t1, label_t1 = next(leading)\n",
    "            img_t2, label_t2 = next(trailing)\n",
    "\n",
    "            # Generate x, y pairs for single samples\n",
    "            x, y = img_sequence(img_t1, img_t2, label_t1, label_t2, label_dict) \n",
    "            yield x, y\n",
    "            \n",
    "        except StopIteration:\n",
    "            # Break the loop if no more samples\n",
    "            break\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_FlatMapDataset element_spec=(TensorSpec(shape=(56, 28, 3), dtype=tf.float32, name=None), TensorSpec(shape=(1,), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Build the validation dataset\n",
    "\n",
    "seed = 123\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: generate_dataset(img_dir_test_lead, img_dir_test_trail, class_names_L, class_names_T, label_dict, image_size = (28,28), seed = None),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(56, 28, 3), dtype=tf.float32),  # shape of x \n",
    "        tf.TensorSpec(shape=(1), dtype=tf.float32)  # shape of y \n",
    "    )\n",
    ") \n",
    "\n",
    "print(val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ LOAD ANNs ################################ \n",
    "dir_bpann = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/bp_ann/model_checkpoint_649_0.67.keras\"\n",
    "dir_pcn = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/model_checkpoint_pcnoriginal_726_0.67.keras\"\n",
    "unzip_path = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/pcn_tt/\"\n",
    "\n",
    "input_layer = tf.keras.layers.Input(shape=(4704,))\n",
    "\n",
    "model = PredictiveCodingNetwork([CustomDense(units=6, activation=\"sigmoid\"),\n",
    "                                 CustomDense(units=4, activation=\"sigmoid\"), \n",
    "                                 CustomDense(units=1, activation=\"sigmoid\")], \n",
    "                                vars=[1, 1, 1], # variances. This is super useless and in the code only the last variance is used\n",
    "                                beta=0.1)\n",
    "\n",
    "keras_file_path = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/model_checkpoint_pcnoriginal_726_0.67.keras\"\n",
    "unzip_path = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/pcn_tt/\"\n",
    "\n",
    "with zipfile.ZipFile(keras_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(unzip_path)\n",
    "\n",
    "# Step 2: Instantiate your custom model with the correct parameters\n",
    "pcn = model # PCN loaded after reinitialising the network\n",
    "\n",
    "# Now `correct_model` has the loaded weights\n",
    "pcn.build([None, 4704])\n",
    "pcn.load_weights(\"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/pcn_tt/model.weights.h5\")\n",
    "\n",
    "pcn.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-7, weight_decay=1e-2),\n",
    "    loss=\"categorical_crossentropy\",  # Placeholder loss\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Backprop ANN\n",
    "bp_ann = tf.keras.models.load_model(dir_bpann)\n",
    "\n",
    "# Some random checks \n",
    "#pcn.infer(tf.random.normal([64, 4704]), return_sequence=True)\n",
    "#[[i.shape for i in j] for j in pcn.infer(tf.random.normal([64, 4704]), return_sequence=True)]\n",
    "# bp_ann(tf.random.normal([64, 4704]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step\n",
      "[[0.3959008 ]\n",
      " [0.3784286 ]\n",
      " [0.38780093]\n",
      " [0.38395813]\n",
      " [0.3791114 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions[:\u001b[38;5;241m5\u001b[39m])  \u001b[38;5;66;03m# Display the first 5 predictions\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mbp_ann\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_val_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/keras/src/trainers/trainer.py:931\u001b[0m, in \u001b[0;36mTrainer._pythonify_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pythonify_logs\u001b[39m(\u001b[38;5;28mself\u001b[39m, logs):\n\u001b[1;32m    930\u001b[0m     result \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 931\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m()):\n\u001b[1;32m    932\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    933\u001b[0m             result\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(value))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "#loss, accuracy = pcn.evaluate((xstack.map(img_preproc).map(flatten), ystack), verbose=0) \n",
    "#loss, accuracy = bp_ann.evaluate(xstack.map(img_preproc).map(flatten), ystack, verbose = 0)\n",
    "#x_data, y_labels = flatten(*img_preproc(xstack, ystack))\n",
    "#loss, accuracy = pcn.evaluate(x_data, y_labels, verbose=0)#\n",
    "\n",
    "#loss, accuracy = pcn.evaluate(val_dataset.map(img_preproc).map(flatten)) \n",
    "#print(f\"Accuracy after training: {accuracy}\")\n",
    "#loss, accuracy = bp_ann.evaluate(val_dataset.batch(512).map(img_preproc).map(flatten))\n",
    "#print(f\"Accuracy after training: {accuracy}\")\n",
    "#bp_ann.predict(val_dataset.batch(512).map(img_preproc).map(flatten))\n",
    "processed_val_dataset = val_dataset.batch(64).map(img_preproc).map(flatten)\n",
    "\n",
    "predictions = bp_ann.predict(val_dataset.batch(64).map(img_preproc).map(flatten)\n",
    ")\n",
    "print(predictions[:5])  # Display the first 5 predictions\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = bp_ann.evaluate(processed_val_dataset)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adamw', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638ms/step\n",
      "[[-0.46771252]\n",
      " [-0.4672056 ]\n",
      " [-0.45892292]\n",
      " [-0.46280956]\n",
      " [-0.46269363]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/keras/src/losses/losses.py:27: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861ms/step - accuracy: 0.6333 - loss: 4.3710e-08\n",
      "Test Loss: 4.371007733539045e-08, Test Accuracy: 0.6333333253860474\n"
     ]
    }
   ],
   "source": [
    "pcn.build([None, 4704])\n",
    "pcn.load_weights(\"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/pcn_tt/model.weights.h5\")\n",
    "\n",
    "pcn.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-7, weight_decay=1e-2),\n",
    "    loss=\"categorical_crossentropy\",  # Placeholder loss\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Prepare the validation dataset with preprocessing, flattening, and batching\n",
    "processed_val_dataset = val_dataset.batch(512).map(img_preproc).map(flatten)\n",
    "\n",
    "# Run predictions\n",
    "predictions = pcn.predict(val_dataset.batch(512).map(img_preproc).map(flatten)\n",
    ")\n",
    "print(predictions[:5])  # Display the first 5 predictions\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = pcn.evaluate(processed_val_dataset)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763ms/step\n",
      "[[0.38204947]\n",
      " [0.37922654]\n",
      " [0.3781236 ]\n",
      " [0.42263642]\n",
      " [0.38012522]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758ms/step - accuracy: 0.6333 - loss: 0.6569\n",
      "Test Loss: 0.6569021344184875, Test Accuracy: 0.6333333253860474\n"
     ]
    }
   ],
   "source": [
    "bp_ann.build([None, 4704])\n",
    "#pcn.load_weights(\"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/pcn_tt/model.weights.h5\")\n",
    "\n",
    "bp_ann.build([None,4704]) \n",
    "bp_ann.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-5, weight_decay=1e-2),\n",
    "              metrics=[\"accuracy\"],\n",
    "              loss=\"BinaryCrossentropy\",  # \"CategoricalCrossentropy\" \"MeanSquaredError\" \n",
    "              )\n",
    "\n",
    "# Prepare the validation dataset with preprocessing, flattening, and batching\n",
    "processed_val_dataset = val_dataset.batch(512).map(img_preproc).map(flatten)\n",
    "\n",
    "# Run predictions\n",
    "predictions = bp_ann.predict(val_dataset.batch(512).map(img_preproc).map(flatten)\n",
    ")\n",
    "print(predictions[:5])  # Display the first 5 predictions\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = bp_ann.evaluate(processed_val_dataset)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "(56, 28, 3) (1,)\n"
     ]
    }
   ],
   "source": [
    "for data, labels in val_dataset.take(1):\n",
    "    print(data.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_with_states(model, x):\n",
    "     outputs = []\n",
    "     for layer in model.layers:\n",
    "          x = layer(x)\n",
    "          outputs.append(x)\n",
    "     return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ MODEL PATHS ################################ \n",
    "dir_bpann = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/bp_ann/model_checkpoint_649_0.67.keras\"\n",
    "dir_pcn = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/model_checkpoint_pcnoriginal_726_0.67.keras\"\n",
    "unzip_path = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/pcn_tt/\"\n",
    "\n",
    "################################ LOAD ANNs ################################ \n",
    "input_layer = tf.keras.layers.Input(shape=(4704,))\n",
    "\n",
    "model = PredictiveCodingNetwork([CustomDense(units=6, activation=\"sigmoid\"),\n",
    "                                 CustomDense(units=4, activation=\"sigmoid\"), \n",
    "                                 CustomDense(units=1, activation=\"sigmoid\")], \n",
    "                                vars=[1, 1, 1], # variances. This is super useless and in the code only the last variance is used\n",
    "                                beta=0.1)\n",
    "\n",
    "keras_file_path = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/model_checkpoint_pcnoriginal_726_0.67.keras\"\n",
    "unzip_path = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/pcn_tt/\"\n",
    "\n",
    "with zipfile.ZipFile(keras_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(unzip_path)\n",
    "\n",
    "# Step 2: Instantiate your custom model with the correct parameters\n",
    "pcn = model # PCN loaded after reinitialising the network\n",
    "\n",
    "# Now `correct_model` has the loaded weights\n",
    "pcn.build([None, 4704])\n",
    "pcn.load_weights(\"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/pcn_tt/model.weights.h5\")\n",
    "\n",
    "pcn.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-7, weight_decay=1e-2),\n",
    "    loss=\"categorical_crossentropy\",  # Placeholder loss\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Backprop ANN\n",
    "bp_ann = tf.keras.models.load_model(dir_bpann)\n",
    "\n",
    "# Some random checks \n",
    "#pcn.infer(tf.random.normal([64, 4704]), return_sequence=True)\n",
    "#[[i.shape for i in j] for j in pcn.infer(tf.random.normal([64, 4704]), return_sequence=True)]\n",
    "# bp_ann(tf.random.normal([64, 4704]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the validation dataset\n",
    "\n",
    "seed = 123\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: generate_dataset(img_dir_test_lead, img_dir_test_trail, class_names_L, class_names_T, label_dict, image_size = (28,28), seed = seed),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(56, 28, 3), dtype=tf.float32),  # shape of x \n",
    "        tf.TensorSpec(shape=(1), dtype=tf.float32)  # shape of y \n",
    "    )\n",
    ") \n",
    "\n",
    "print(val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denisekittelmann/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/keras/src/saving/saving_api.py:107: UserWarning: You are saving a model that has not yet been built. It might not contain any weights yet. Consider building the model first by calling it on some data.\n",
      "  return saving_lib.save_model(model, filepath)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = PredictiveCodingNetwork(vars=[1, 1, 1], beta=0.1)\n",
    "\n",
    "# Load weights\n",
    "dir_pcn = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/model_checkpoint_pcnoriginal_726_0.67.keras\"\n",
    "model.load_weights(dir_pcn)\n",
    "\n",
    "# Save to a new file\n",
    "updated_dir_pcn = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/updated_model_checkpoint.keras\"\n",
    "model.save(updated_dir_pcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDense(tf.keras.layers.Dense):\n",
    "    def call(self, inputs):\n",
    "        \"\"\"This works like a dense, except for the activation being called earlier.\"\"\"\n",
    "        # Apply the activation to the input first\n",
    "        activated_input = self.activation(inputs)\n",
    "        # Perform the matrix multiplication and add the bias\n",
    "        output = tf.matmul(activated_input, self.kernel)\n",
    "        if self.use_bias:\n",
    "            output = output + self.bias\n",
    "        return output\n",
    "\n",
    "\n",
    "class PredictiveCodingNetwork(tf.keras.Sequential):\n",
    "    def __init__(self, layers, vars, beta, **kwargs):\n",
    "        \"\"\"Initialize a PredictiveCodingNetwork\"\"\"\n",
    "        super().__init__(layers, **kwargs)\n",
    "        self.vars = tf.convert_to_tensor(vars, dtype=tf.float32)\n",
    "        self.beta = beta\n",
    "\n",
    "    def call_with_states(self, x):\n",
    "        x_list = [x]\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            x_list.append(x)\n",
    "        return x_list\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        x, y = data\n",
    "\n",
    "        # do the stuff we do in train_epochs\n",
    "        outputs, errors = self.infer(x, y)\n",
    "        self.update_params(outputs, errors)\n",
    "\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        pred = self.call(x)\n",
    "        for metric in self.metrics:\n",
    "            metric.update_state(y, pred)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "   \n",
    "    def infer(self, x_batch, y_batch=None, n_iter=50, return_sequence=False):\n",
    "        \"\"\"Note: while model call, call with states and model evaluate take\n",
    "        2D input, train_step and infer take stacked 3D inputs.\"\"\"\n",
    "        if return_sequence:\n",
    "            errors_time = []\n",
    "            states_time = []\n",
    "        errors = [None for _ in range(len(self.layers))]\n",
    "        f_x_arr = [None for _ in range(len(self.layers))]\n",
    "        f_x_deriv_arr = [None for _ in range(len(self.layers))]\n",
    "        shape = x_batch.shape\n",
    "        batch_size = shape[0]\n",
    "\n",
    "        for itr in range(n_iter):\n",
    "            # if its the first itr, set x to the current forward call\n",
    "            if itr == 0:\n",
    "                x = self.call_with_states(x_batch)\n",
    "\n",
    "                if y_batch is not None:\n",
    "                  x[-1] = y_batch\n",
    "            else:\n",
    "                # update g and x only for consecutive iterations\n",
    "                for l in range(1, len(self.layers)):\n",
    "                    g = tf.multiply(tf.matmul(errors[l], self.layers[l].kernel, transpose_b=True), f_x_deriv_arr[l])\n",
    "                    x[l] = x[l] + self.beta * (-errors[l-1] + g)\n",
    "\n",
    "            # update f_x etc for every iteration\n",
    "            for l in range(len(self.layers)):\n",
    "                f_x = self.layers[l].activation(x[l])\n",
    "                f_x_deriv_fn = self.get_activation_derivative(self.layers[l].activation)\n",
    "                f_x_deriv = f_x_deriv_fn(x[l])\n",
    "                f_x_arr[l] = f_x\n",
    "                f_x_deriv_arr[l] = f_x_deriv\n",
    "                errors[l] = (x[l + 1] - tf.matmul(f_x, self.layers[l].kernel) - self.layers[l].bias) / self.vars[l]\n",
    "            \n",
    "            if return_sequence:\n",
    "                errors_time.append(errors)\n",
    "                states_time.append(x)\n",
    "\n",
    "        # return what we want to return\n",
    "        if return_sequence:\n",
    "            states_time = [tf.stack(tensors, axis=1) for tensors in zip(*states_time)]\n",
    "            errors_time = [tf.stack(tensors, axis=1) for tensors in zip(*errors_time)]\n",
    "            return states_time, errors_time\n",
    "        else:\n",
    "            return x, errors\n",
    "    \n",
    "    # We need to check if we actually need call here.\n",
    "    # Now, call will give us the result of the network after the first inference step\n",
    "    # If we want to have the results after the last inference step, we would need to change this\n",
    "    #def call(self, inputs, training=False):\n",
    "    #    \"\"\"Call, but time distributed.\"\"\"\n",
    "    #    x, errors = self.infer(inputs, return_sequence=False)\n",
    "    #    return x[-1]\n",
    "\n",
    "    def update_params(self, x, errors):\n",
    "        \"\"\"Update the model parameters.\"\"\"\n",
    "        batch_size = tf.cast(tf.shape(x[0])[0], tf.float32)\n",
    "        gradients = []\n",
    "        for l, layer in enumerate(self.layers):\n",
    "            grad_w = self.vars[-1] * (1 / batch_size) * tf.matmul(tf.transpose(self.layers[l].activation(x[l])), errors[l])\n",
    "            grad_b = self.vars[-1] * (1 / batch_size) * tf.reduce_sum(errors[l], axis=0)\n",
    "            gradients.append((-grad_w, layer.kernel))\n",
    "            gradients.append((-grad_b, layer.bias))\n",
    "        self.optimizer.apply_gradients(gradients)\n",
    "\n",
    "    def get_activation_derivative(self, activation):\n",
    "        \"\"\"Return a function for the derivative of the given activation function.\"\"\"\n",
    "        activation_fn = tf.keras.activations.get(activation)\n",
    "        if activation_fn == tf.keras.activations.linear:\n",
    "            return lambda x: tf.ones_like(x)\n",
    "        elif activation_fn == tf.keras.activations.tanh:\n",
    "            return lambda x: 1 - tf.square(tf.nn.tanh(x))\n",
    "        elif activation_fn == tf.keras.activations.sigmoid:\n",
    "            return lambda x: tf.nn.sigmoid(x) * (1 - tf.nn.sigmoid(x))\n",
    "        else:\n",
    "            raise ValueError(f\"{activation} not supported\")\n",
    "        \n",
    "\n",
    "model = PredictiveCodingNetwork([CustomDense(units=6, activation=\"sigmoid\"),\n",
    "                                 CustomDense(units=4, activation=\"sigmoid\"), \n",
    "                                 CustomDense(units=1, activation=\"sigmoid\")], \n",
    "                                vars=[1, 1, 1], # variances. This is super useless and in the code only the last variance is used\n",
    "                                beta=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layers added to a Sequential model can only have a single positional argument, the input tensor. Layer InputLayer has multiple positional arguments: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/keras/src/models/sequential.py:186\u001b[0m, in \u001b[0;36mSequential.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;66;03m# Can happen if shape inference is not implemented.\u001b[39;00m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/BiMo_3.9/lib/python3.9/inspect.py:3045\u001b[0m, in \u001b[0;36mSignature.bind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3041\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[1;32m   3042\u001b[0m \u001b[38;5;124;03mand `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[1;32m   3043\u001b[0m \u001b[38;5;124;03mif the passed arguments can not be bound.\u001b[39;00m\n\u001b[1;32m   3044\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3045\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/BiMo_3.9/lib/python3.9/inspect.py:2966\u001b[0m, in \u001b[0;36mSignature._bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   2965\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m-> 2966\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoo many positional arguments\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2967\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: too many positional arguments",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m dir_pcn \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/model_checkpoint_pcnoriginal_726_0.67.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#test = tf.keras.models.load_model(dir_pcn, compile = False)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m pcn \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdir_pcn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCustomDense\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mCustomDense\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPredictiveCodingNetwork\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mPredictiveCodingNetwork\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/keras/src/saving/saving_api.py:187\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    184\u001b[0m         is_keras_zip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip \u001b[38;5;129;01mor\u001b[39;00m is_keras_dir:\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[1;32m    195\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[1;32m    196\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:365\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    361\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid filename: expected a `.keras` extension. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m     )\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_model_from_fileobj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:442\u001b[0m, in \u001b[0;36m_load_model_from_fileobj\u001b[0;34m(fileobj, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zf\u001b[38;5;241m.\u001b[39mopen(_CONFIG_FILENAME, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    440\u001b[0m     config_json \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 442\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43m_model_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m all_filenames \u001b[38;5;241m=\u001b[39m zf\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[1;32m    447\u001b[0m extract_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:431\u001b[0m, in \u001b[0;36m_model_from_config\u001b[0;34m(config_json, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[0;32m--> 431\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/keras/src/saving/serialization_lib.py:718\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m custom_obj_scope, safe_mode_scope:\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m         instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    720\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    721\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m could not be deserialized properly. Please\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    722\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ensure that components that are Python object\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    727\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/keras/src/models/sequential.py:360\u001b[0m, in \u001b[0;36mSequential.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    354\u001b[0m     model\u001b[38;5;241m.\u001b[39madd(layer)\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39m_functional\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m build_input_shape\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(build_input_shape, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m))\n\u001b[1;32m    359\u001b[0m ):\n\u001b[0;32m--> 360\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuild_input_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/keras/src/layers/layer.py:226\u001b[0m, in \u001b[0;36mLayer.__new__.<locals>.build_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[1;32m    225\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m current_path()\n\u001b[0;32m--> 226\u001b[0m     \u001b[43moriginal_build_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(original_build_method)\n",
      "File \u001b[0;32m~/miniconda3/envs/BiMo_3.9/lib/python3.9/site-packages/keras/src/models/sequential.py:199\u001b[0m, in \u001b[0;36mSequential.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    193\u001b[0m         positional_args \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    194\u001b[0m             param\n\u001b[1;32m    195\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m signature\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    196\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mdefault \u001b[38;5;241m==\u001b[39m inspect\u001b[38;5;241m.\u001b[39mParameter\u001b[38;5;241m.\u001b[39mempty\n\u001b[1;32m    197\u001b[0m         ]\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(positional_args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 199\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    200\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayers added to a Sequential model \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    201\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan only have a single positional argument, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe input tensor. Layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas multiple positional arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpositional_args\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m             )\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m x\n",
      "\u001b[0;31mValueError\u001b[0m: Layers added to a Sequential model can only have a single positional argument, the input tensor. Layer InputLayer has multiple positional arguments: []"
     ]
    }
   ],
   "source": [
    "dir_pcn = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/model_checkpoint_pcnoriginal_726_0.67.keras\"\n",
    "#test = tf.keras.models.load_model(dir_pcn, compile = False)\n",
    "\n",
    "pcn = tf.keras.models.load_model(\n",
    "    dir_pcn,\n",
    "    custom_objects={\n",
    "        \"CustomDense\": CustomDense,\n",
    "        \"PredictiveCodingNetwork\": PredictiveCodingNetwork\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: generate_dataset(img_dir_test_lead, img_dir_test_trail, class_names_L, class_names_T, label_dict, image_size = (28,28), seed = seed),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(56, 28, 3), dtype=tf.float32),  # shape of x \n",
    "        tf.TensorSpec(shape=(1), dtype=tf.float32)  # shape of y \n",
    "    )\n",
    ") \n",
    "\n",
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"predictive_coding_network_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"predictive_coding_network_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ custom_dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomDense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">28,230</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ custom_dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomDense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ custom_dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomDense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ custom_dense_24 (\u001b[38;5;33mCustomDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │        \u001b[38;5;34m28,230\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ custom_dense_25 (\u001b[38;5;33mCustomDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m28\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ custom_dense_26 (\u001b[38;5;33mCustomDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,263</span> (110.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m28,263\u001b[0m (110.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,263</span> (110.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m28,263\u001b[0m (110.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Step 1: Unzip the .keras file to access its internal structure\n",
    "keras_file_path = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/model_checkpoint_pcnoriginal_726_0.67.keras\"\n",
    "unzip_path = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/pcn_tt/\"\n",
    "\n",
    "with zipfile.ZipFile(keras_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(unzip_path)\n",
    "\n",
    "# Step 2: Instantiate your custom model with the correct parameters\n",
    "correct_model = model # Replace with your model parameters\n",
    "\n",
    "# Step 3: Use a checkpoint to load weights from the 'variables' directory\n",
    "#checkpoint = tf.train.Checkpoint(model=correct_model)\n",
    "#checkpoint.restore(os.path.join(unzip_path)).assert_existing_objects_matched()\n",
    "\n",
    "# Now `correct_model` has the loaded weights\n",
    "correct_model.build([None, 4704])\n",
    "correct_model.load_weights(\"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/pcn_tt/model.weights.h5\")\n",
    "\n",
    "64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: generate_dataset(img_dir_test_lead, img_dir_test_trail, class_names_L, class_names_T, label_dict, image_size = (28,28), seed = seed),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(56, 28, 3), dtype=tf.float32),  # shape of x \n",
    "        tf.TensorSpec(shape=(1), dtype=tf.float32)  # shape of y \n",
    "    )\n",
    ") \n",
    "\n",
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BiMo_3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
