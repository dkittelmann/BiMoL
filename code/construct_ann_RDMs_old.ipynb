{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import scipy.io\n",
    "from scipy.spatial.distance import cosine\n",
    "import zipfile\n",
    "import itertools\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ CONDITION MAPPINGS ################################ \n",
    "\n",
    "#Idea: we create a customised event_id dict that allows us to later just extract \n",
    "    # the trailing images corresponding to our transitional probabiliy categories\n",
    "\n",
    "    # Mapping VALID CONDITIONS (75%): \n",
    "        # leading_barn -> trailing_church\n",
    "        # leading_beach -> trailing_church\n",
    "        # leading_library -> trailing_conference_room\n",
    "        # leading_restaurant ->  trailing_conference_room\n",
    "\n",
    "    # Mapping INVALID CONDITIONS (25%): \n",
    "        # leading_barn -> trailing_conference_room\n",
    "        # leading_beach -> trailing_conference_room\n",
    "        # leading_library -> trailing_church\n",
    "        # leading_restaurant -> trailing_church\n",
    "        \n",
    "    # Mapping CONTROL CONDITIONS (50%): \n",
    "        # leading_cave -> trailing_castle\n",
    "        # leading_cave -> trailing_forest\n",
    "        \n",
    "\n",
    "# Create label_dict according to labels used during training\n",
    "label_dict = {\n",
    "    (0, 1): 0.75, (1, 1): 0.75,\n",
    "    (3, 2): 0.75, (4, 2): 0.75,\n",
    "    (0, 2): 0.25, (1, 2): 0.25,\n",
    "    (3, 1): 0.25, (4, 1): 0.25,\n",
    "    (2, 0): 0.5,\n",
    "    (2, 3): 0.5\n",
    "}\n",
    "\n",
    "# Leading dict\n",
    "lead_dict = {\n",
    "    \"barn\": 0,\n",
    "    \"beach\": 1,\n",
    "    \"cave\": 2,\n",
    "    \"library\": 3,\n",
    "    \"restaurant\": 4\n",
    "}\n",
    "\n",
    "# Trailing dict\n",
    "trail_dict = {\n",
    "    \"Church\": 1,\n",
    "    \"castle\": 0,\n",
    "    \"conference_room\": 2,\n",
    "    \"forest\": 3\n",
    "}\n",
    "\n",
    "# Dict for RDM mappings\n",
    "rdm_dict = {\n",
    "    0: ((0, 1), (1, 1)),  # 0.75%: barn -> church, beach -> church\n",
    "    1: ((3, 2), (4, 2)),  # 0.75%: library -> conference room, restaurant -> conference room\n",
    "    2: ((0, 2), (1, 2)),  # 0.25%: barn -> conference room, beach -> conference room\n",
    "    3: ((3, 1), (4, 1)),  # 0.25%: library -> church, restaurant -> church\n",
    "    4: ((2, 0),),         # 0.5%: cave -> castle\n",
    "    5: ((2, 3),)          # 0.5%: cave -> forest\n",
    "}\n",
    "\n",
    "\n",
    "category_dict = {\n",
    "    0: (0, 5), # valid conditions 75 %\n",
    "    1: (1, 5), # leading_beach -> trailing_church\n",
    "    2: (2, 6), # leading_library -> trailing_conference_room\n",
    "    3: (3, 6),  # leading_restaurant ->  trailing_conference_room\n",
    "    4: (0, 6), # invalid conditions 0.25 %\n",
    "    5: (1, 6),\n",
    "    6: (2, 5), \n",
    "    7: (3, 5), \n",
    "    8: (4, 7), # control conditions 50 %\n",
    "    9: (4, 8)\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ HELPER FUNCTIONS ################################ \n",
    "\n",
    "def generate_possible_img_pairings(rdm_dict, category_id, img_dirt1, img_dirt2, class_namest1, class_namest2, label_dict, image_size=(28, 28), seed=None):\n",
    "    '''This function generates a dataset with all possible image combinations based on rdm_dict.'''\n",
    "\n",
    "    data_t1 = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        img_dirt1,\n",
    "        label_mode='int',\n",
    "        class_names=class_namest1,\n",
    "        batch_size=None,\n",
    "        color_mode='rgb',\n",
    "        image_size=image_size,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    data_t2 = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        img_dirt2,\n",
    "        label_mode='int',\n",
    "        class_names=class_namest2,\n",
    "        batch_size=None,\n",
    "        color_mode='rgb',\n",
    "        image_size=image_size,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "\n",
    "    l_data_t1 = list(data_t1)\n",
    "    l_data_t2 = list(data_t2)\n",
    "\n",
    "\n",
    "    x_pairs = []\n",
    "    y_labels = []\n",
    "\n",
    "    # Generate pairs for the specified category_id\n",
    "    if category_id in rdm_dict:\n",
    "        pairs = rdm_dict[category_id]\n",
    "        for lead, trail in pairs:\n",
    "            # Filter images by label in data_t1 and data_t2 for the current lead and trail categories\n",
    "            lead_images = [img for img, lbl in l_data_t1 if lbl.numpy() == lead]\n",
    "            trail_images = [img for img, lbl in l_data_t2 if lbl.numpy() == trail]\n",
    "\n",
    "            # Generate all possible combinations of image pairs according to current leading and trailing image category\n",
    "            for img_t1, img_t2 in itertools.product(lead_images, trail_images):\n",
    "                # Concatenate images along the height dimension -> (56, 28, 3)\n",
    "                x = tf.concat([img_t1, img_t2], axis=0)  \n",
    "                label = label_dict[(lead, trail)] \n",
    "                y = tf.cast(tf.random.uniform([]) < label, tf.float32) \n",
    "                y = tf.expand_dims(y, axis=0) \n",
    "\n",
    "                x_pairs.append(x)  \n",
    "                y_labels.append(y)  \n",
    "\n",
    "    # Concatenate all pairs and the correspondin labels  \n",
    "    x_stacked = tf.concat([tf.expand_dims(x, axis=0) for x in x_pairs], axis=0)\n",
    "    y_stacked = tf.concat([tf.expand_dims(y, axis=0) for y in y_labels], axis=0)\n",
    "    \n",
    "    return tf.data.Dataset.from_tensors((x_stacked, y_stacked))\n",
    "  \n",
    "\n",
    "def tf_f_inv(x, act_fn):\n",
    "    \"\"\" (activation_size, batch_size) \"\"\"\n",
    "    if act_fn == \"LINEAR\":\n",
    "        m = x\n",
    "    elif act_fn == \"TANH\":\n",
    "        num = tf.ones_like(x) + x\n",
    "        div = tf.ones_like(x) - x + 1e-7\n",
    "        m = 0.5 * tf.math.log(num / div)\n",
    "    elif act_fn == \"LOGSIG\":\n",
    "        div = tf.ones_like(x) - x + 1e-7\n",
    "        m = tf.math.log((x / div) + 1e-7)\n",
    "    else:\n",
    "        raise ValueError(f\"{act_fn} not supported\")\n",
    "    return m\n",
    "\n",
    "\n",
    "def img_preproc(x, y, dtype=tf.float32): \n",
    "  \"\"\"Cast input image to a certain tf dtype and normalize them between 0 and 1.\"\"\"\n",
    "  x = tf.cast(x, dtype) / 255.\n",
    "  #x = tf_scale_imgs(x, cf.img_scale)\n",
    "  #y = tf_scale_labels(y, cf.label_scale)\n",
    "  #x = tf_f_inv(x, \"TANH\")\n",
    "  #y = tf.one_hot(y, depth=10)\n",
    "  return x, y\n",
    "\n",
    "\n",
    "def flatten(x, y):  \n",
    "  #flattens a video image series (or batch of images) to (n_batch, n_steps, 1) d.\n",
    "  shape = tf.shape(x)\n",
    "  if len(shape) == 5: # hack, determining if it's a video or not (batch_size, n_steps, height, width, channels)\n",
    "    x = tf.reshape(x, [shape[0], shape[1], -1])\n",
    "  elif len(shape) == 4: # regular image (batch_size, height, width, channels)\n",
    "    x = tf.reshape(x, [shape[0], -1])\n",
    "  elif len(shape) == 3:  # Single image (height, width, channels)\n",
    "    x = tf.reshape(x, [-1])\n",
    "  return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ RELOAD PCN ################################ \n",
    "\n",
    "# To reload the PCN, we need to call the model once again and nee the specific customed Dense layer model itself. \n",
    "\n",
    "class CustomDense(tf.keras.layers.Dense):\n",
    "    def call(self, inputs):\n",
    "        \"\"\"This works like a dense, except for the activation being called earlier.\"\"\"\n",
    "        # Apply the activation to the input first\n",
    "        activated_input = self.activation(inputs)\n",
    "        # Perform the matrix multiplication and add the bias\n",
    "        output = tf.matmul(activated_input, self.kernel)\n",
    "        if self.use_bias:\n",
    "            output = output + self.bias\n",
    "        return output\n",
    "\n",
    "\n",
    "class PredictiveCodingNetwork(tf.keras.Sequential):\n",
    "    def __init__(self, layers, vars, beta, **kwargs):\n",
    "        \"\"\"Initialize a PredictiveCodingNetwork\"\"\"\n",
    "        super().__init__(layers, **kwargs)\n",
    "        self.vars = tf.convert_to_tensor(vars, dtype=tf.float32)\n",
    "        self.beta = beta\n",
    "\n",
    "    def call_with_states(self, x):\n",
    "        x_list = [x]\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            x_list.append(x)\n",
    "        return x_list\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        x, y = data\n",
    "\n",
    "        # do the stuff we do in train_epochs\n",
    "        outputs, errors = self.infer(x, y)\n",
    "        self.update_params(outputs, errors)\n",
    "\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        pred = self.call(x)\n",
    "        for metric in self.metrics:\n",
    "            metric.update_state(y, pred)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "   \n",
    "    def infer(self, x_batch, y_batch=None, n_iter=50, return_sequence=False):\n",
    "        \"\"\"Note: while model call, call with states and model evaluate take\n",
    "        2D input, train_step and infer take stacked 3D inputs.\"\"\"\n",
    "        if return_sequence:\n",
    "            errors_time = []\n",
    "            states_time = []\n",
    "        errors = [None for _ in range(len(self.layers))]\n",
    "        f_x_arr = [None for _ in range(len(self.layers))]\n",
    "        f_x_deriv_arr = [None for _ in range(len(self.layers))]\n",
    "        shape = x_batch.shape\n",
    "        batch_size = shape[0]\n",
    "\n",
    "        for itr in range(n_iter):\n",
    "            # if its the first itr, set x to the current forward call\n",
    "            if itr == 0:\n",
    "                x = self.call_with_states(x_batch)\n",
    "\n",
    "                if y_batch is not None:\n",
    "                  x[-1] = y_batch\n",
    "            else:\n",
    "                # update g and x only for consecutive iterations\n",
    "                for l in range(1, len(self.layers)):\n",
    "                    g = tf.multiply(tf.matmul(errors[l], self.layers[l].kernel, transpose_b=True), f_x_deriv_arr[l])\n",
    "                    x[l] = x[l] + self.beta * (-errors[l-1] + g)\n",
    "\n",
    "            # update f_x etc for every iteration\n",
    "            for l in range(len(self.layers)):\n",
    "                f_x = self.layers[l].activation(x[l])\n",
    "                f_x_deriv_fn = self.get_activation_derivative(self.layers[l].activation)\n",
    "                f_x_deriv = f_x_deriv_fn(x[l])\n",
    "                f_x_arr[l] = f_x\n",
    "                f_x_deriv_arr[l] = f_x_deriv\n",
    "                errors[l] = (x[l + 1] - tf.matmul(f_x, self.layers[l].kernel) - self.layers[l].bias) / self.vars[l]\n",
    "            \n",
    "            if return_sequence:\n",
    "                errors_time.append(errors)\n",
    "                states_time.append(x)\n",
    "\n",
    "        # return what we want to return\n",
    "        if return_sequence:\n",
    "            states_time = [tf.stack(tensors, axis=1) for tensors in zip(*states_time)]\n",
    "            errors_time = [tf.stack(tensors, axis=1) for tensors in zip(*errors_time)]\n",
    "            return states_time, errors_time\n",
    "        else:\n",
    "            return x, errors\n",
    "    \n",
    "    # We need to check if we actually need call here.\n",
    "    # Now, call will give us the result of the network after the first inference step\n",
    "    # If we want to have the results after the last inference step, we would need to change this\n",
    "    #def call(self, inputs, training=False):\n",
    "    #    \"\"\"Call, but time distributed.\"\"\"\n",
    "    #    x, errors = self.infer(inputs, return_sequence=False)\n",
    "    #    return x[-1]\n",
    "\n",
    "    def update_params(self, x, errors):\n",
    "        \"\"\"Update the model parameters.\"\"\"\n",
    "        batch_size = tf.cast(tf.shape(x[0])[0], tf.float32)\n",
    "        gradients = []\n",
    "        for l, layer in enumerate(self.layers):\n",
    "            grad_w = self.vars[-1] * (1 / batch_size) * tf.matmul(tf.transpose(self.layers[l].activation(x[l])), errors[l])\n",
    "            grad_b = self.vars[-1] * (1 / batch_size) * tf.reduce_sum(errors[l], axis=0)\n",
    "            gradients.append((-grad_w, layer.kernel))\n",
    "            gradients.append((-grad_b, layer.bias))\n",
    "        self.optimizer.apply_gradients(gradients)\n",
    "\n",
    "    def get_activation_derivative(self, activation):\n",
    "        \"\"\"Return a function for the derivative of the given activation function.\"\"\"\n",
    "        activation_fn = tf.keras.activations.get(activation)\n",
    "        if activation_fn == tf.keras.activations.linear:\n",
    "            return lambda x: tf.ones_like(x)\n",
    "        elif activation_fn == tf.keras.activations.tanh:\n",
    "            return lambda x: 1 - tf.square(tf.nn.tanh(x))\n",
    "        elif activation_fn == tf.keras.activations.sigmoid:\n",
    "            return lambda x: tf.nn.sigmoid(x) * (1 - tf.nn.sigmoid(x))\n",
    "        else:\n",
    "            raise ValueError(f\"{activation} not supported\")\n",
    "        \n",
    "def call_with_states(model, x):\n",
    "     outputs = []\n",
    "     for layer in model.layers:\n",
    "          x = layer(x)\n",
    "          outputs.append(x)\n",
    "     return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ MODEL PATHS ################################ \n",
    "dir_bpann = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/bp_ann/model_checkpoint_649_0.67.keras\"\n",
    "dir_pcn = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/model_checkpoint_pcnoriginal_726_0.67.keras\"\n",
    "unzip_path = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/pcn_tt/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ LOAD ANNs ################################ \n",
    "input_layer = tf.keras.layers.Input(shape=(4704,))\n",
    "\n",
    "model = PredictiveCodingNetwork([CustomDense(units=6, activation=\"sigmoid\"),\n",
    "                                 CustomDense(units=4, activation=\"sigmoid\"), \n",
    "                                 CustomDense(units=1, activation=\"sigmoid\")], \n",
    "                                vars=[1, 1, 1], # variances. This is super useless and in the code only the last variance is used\n",
    "                                beta=0.1)\n",
    "\n",
    "keras_file_path = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/model_checkpoint_pcnoriginal_726_0.67.keras\"\n",
    "unzip_path = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/pcn_tt/\"\n",
    "\n",
    "with zipfile.ZipFile(keras_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(unzip_path)\n",
    "\n",
    "# Step 2: Instantiate your custom model with the correct parameters\n",
    "pcn = model # PCN loaded after reinitialising the network\n",
    "\n",
    "# Now `correct_model` has the loaded weights\n",
    "pcn.build([None, 4704])\n",
    "pcn.load_weights(\"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/pcn_tt/model.weights.h5\")\n",
    "\n",
    "pcn.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-7, weight_decay=1e-2),\n",
    "    loss=\"categorical_crossentropy\",  # Placeholder loss\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Backprop ANN\n",
    "bp_ann = tf.keras.models.load_model(dir_bpann)\n",
    "\n",
    "# Some random checks \n",
    "#pcn.infer(tf.random.normal([64, 4704]), return_sequence=True)\n",
    "#[[i.shape for i in j] for j in pcn.infer(tf.random.normal([64, 4704]), return_sequence=True)]\n",
    "# bp_ann(tf.random.normal([64, 4704]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing category_id: 0\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Processing category_id: 1\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing category_id: 2\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing category_id: 3\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing category_id: 4\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing category_id: 5\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "RDM Matrix:\n",
      "[[0.00000000e+00 3.88539038e-08 0.00000000e+00 0.00000000e+00\n",
      "  3.75434434e-08 1.48837525e-08]\n",
      " [3.88539038e-08 0.00000000e+00 5.90855265e-09 1.80949293e-08\n",
      "  4.02510205e-08 3.02408644e-08]\n",
      " [0.00000000e+00 5.90855265e-09 8.18454959e-09 0.00000000e+00\n",
      "  1.44218276e-08 0.00000000e+00]\n",
      " [0.00000000e+00 1.80949293e-08 0.00000000e+00 9.54488411e-09\n",
      "  3.28869776e-09 0.00000000e+00]\n",
      " [3.75434434e-08 4.02510205e-08 1.44218276e-08 3.28869776e-09\n",
      "  9.26334587e-09 0.00000000e+00]\n",
      " [1.48837525e-08 3.02408644e-08 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Initialize the RDM matrix\n",
    "category_ids = len(rdm_dict)\n",
    "rdm_h1_pcn_act = np.zeros((6,6))\n",
    "\n",
    "# Dictionary to cache mean activations for each category\n",
    "category_activations = []\n",
    "\n",
    "# Calculate and cache mean activations for each category only once\n",
    "for category_id in range(category_ids):\n",
    "    print(f\"Processing category_id: {category_id}\")\n",
    "    \n",
    "    # Generate possible image pairings for the given category without creating a batch\n",
    "    val_dataset = generate_possible_img_pairings(\n",
    "        rdm_dict, category_id, img_dir_test_lead, img_dir_test_trail, class_names_L, class_names_T, label_dict, image_size=(28, 28), seed=seed\n",
    "    )\n",
    "\n",
    "    # Preprocess and flatten the dataset without batching\n",
    "    val_dataset = val_dataset.map(img_preproc).map(flatten)\n",
    "\n",
    "    # Retrieve all image pairs and labels in the dataset (assuming a single batch dataset)\n",
    "    x_pairs, y_labels = next(iter(val_dataset))\n",
    "\n",
    "    # Predict activations for the current category's image pairs\n",
    "    pcn_acts = correct_model.predict(x_pairs)\n",
    "\n",
    "    # Calculate and store the mean activation for this category\n",
    "    mean_activation = np.mean(pcn_acts, axis=0).reshape(-1)\n",
    "    category_activations.append(mean_activation)  # Store the exact vector used for all comparisons\n",
    "\n",
    "# Calculate cosine similarities between the mean activations to populate the RDM\n",
    "for i in range(category_ids):\n",
    "    for j in range(category_ids):\n",
    "        arr_i = category_activations[i]\n",
    "        arr_j = category_activations[j]\n",
    "        rdm_h1_pcn_act[i, j] = cosine(arr_i, arr_j)\n",
    "\n",
    "        # Calculate cosine similarity between the mean activations\n",
    "        #rdm_h1_pcn_act[i, j] = cosine(mean_activation_i, mean_activation_j)\n",
    "\n",
    "# Display the RDM matrix\n",
    "print(\"RDM Matrix:\")\n",
    "print(rdm_h1_pcn_act)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ IMAGE PATHS ################################ \n",
    "\n",
    "img_dir_lead = '/Users/denisekittelmann/Documents/Python/BiMoL/data/Leading/'\n",
    "img_dir_trail = '/Users/denisekittelmann/Documents/Python/BiMoL/data/Trailing/'\n",
    "img_dir_test_lead = '/Users/denisekittelmann/Documents/Python/BiMoL/data/Test/Test_Leading/'\n",
    "img_dir_test_trail = '/Users/denisekittelmann/Documents/Python/BiMoL/data/Test/Test_Trailing/'\n",
    "class_names_L = ['barn', 'beach', 'cave', 'library', 'restaurant']\n",
    "class_names_T = ['castle', 'Church', 'conference_room', 'forest'] # changed the order \n",
    "batch_size = None # adjust if needed, e.g., 32\n",
    "image_size = (28,28)\n",
    "validation_split = 0.1\n",
    "seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ RESULT PATHS ################################ \n",
    "results_path_pcn = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/rdms/ann_RDM/pcn/\"\n",
    "results_path_bp = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/rdms/ann_RDM/backprop/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    (0, 1): 0.0, (1, 1): 0.0,\n",
    "    (3, 2): 0.0, (4, 2): 0.0,\n",
    "    (0, 2): 0.75, (1, 2): 0.75,\n",
    "    (3, 1): 0.75, (4, 1): 0.75,\n",
    "    (2, 0): 0.5,\n",
    "    (2, 3): 0.5\n",
    "}\n",
    "\n",
    "lead_cat = {\n",
    "    \"barn\": 0,\n",
    "    \"beach\": 1,\n",
    "    \"cave\": 2,\n",
    "    \"library\": 3,\n",
    "    \"restaurant\": 4\n",
    "}\n",
    "\n",
    "trail_cat = {\n",
    "    \"church\": 1,\n",
    "    \"castle\": 0,\n",
    "    \"conference_room\": 2,\n",
    "    \"forest\": 3\n",
    "}\n",
    "\n",
    "rdm_dict = {\n",
    "    0: ((0, 1), (1, 1)),  # 0.75%: barn -> church, beach -> church\n",
    "    1: ((3, 2), (4, 2)),  # 0.75%: library -> conference room, restaurant -> conference room\n",
    "    2: ((0, 2), (1, 2)),  # 0.25%: barn -> conference room, beach -> conference room\n",
    "    3: ((3, 1), (4, 1)),  # 0.25%: library -> church, restaurant -> church\n",
    "    4: ((2, 0),),         # 0.5%: cave -> castle\n",
    "    5: ((2, 3),)          # 0.5%: cave -> forest\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Generator function to produce specific combinations as defined by rdm_dict\n",
    "def generate_specific_combination(category_id, rdm_dict, img_dirt1, img_dirt2, class_namest1, class_namest2, label_dict, image_size=(28, 28), seed=None): \n",
    "    # Load images from both directories without batching\n",
    "    data_t1 = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        img_dirt1, \n",
    "        label_mode='int',\n",
    "        class_names=class_namest1,\n",
    "        batch_size=None,\n",
    "        color_mode='rgb',\n",
    "        image_size=image_size,\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    data_t2 = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        img_dirt2, \n",
    "        label_mode='int',\n",
    "        class_names=class_namest2,\n",
    "        batch_size=None,\n",
    "        color_mode='rgb',\n",
    "        image_size=image_size,\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    # Convert datasets to lists for pairing\n",
    "    data_t1_list = list(data_t1)\n",
    "    data_t2_list = list(data_t2)\n",
    "\n",
    "    x_pairs = []\n",
    "    y_labels = []\n",
    "\n",
    "    # Only process the specified category_id in rdm_dict\n",
    "    if category_id in rdm_dict:\n",
    "        pairs = rdm_dict[category_id]\n",
    "        for lead, trail in pairs:\n",
    "            # Filter images by label in data_t1 and data_t2 for the current lead and trail categories\n",
    "            lead_images = [img for img, lbl in data_t1_list if lbl.numpy() == lead]\n",
    "            trail_images = [img for img, lbl in data_t2_list if lbl.numpy() == trail]\n",
    "\n",
    "            # Pair each lead image with each trail image\n",
    "            for img_t1, img_t2 in itertools.product(lead_images, trail_images):\n",
    "                # Concatenate images and assign labels based on label_dict\n",
    "                x, y = img_sequence(img_t1, img_t2, lead, trail, label_dict)\n",
    "                if x is not None:\n",
    "                    x_pairs.append(x)\n",
    "                    y_labels.append(y)\n",
    "\n",
    "    # Stack pairs and labels if they exist\n",
    "        x_stacked = tf.stack(x_pairs, axis=0)\n",
    "        y_stacked = tf.stack(y_labels, axis=0)\n",
    "        return x_stacked, y_stacked\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Combined dataset - x shape: (3240, 56, 28, 3), y shape: (3240, 1)\n",
      "Combined x shape: (3240, 56, 28, 3), Combined y shape: (3240, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_possible_img_pairings(rdm_dict, category_id, img_dirt1, img_dirt2, class_namest1, class_namest2, label_dict, image_size=(28, 28), seed=None):\n",
    "    '''This function generates a dataset with all possible image combinations based on rdm_dict.'''\n",
    "\n",
    "    data_t1 = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        img_dirt1,\n",
    "        label_mode='int',\n",
    "        class_names=class_namest1,\n",
    "        batch_size=None,\n",
    "        color_mode='rgb',\n",
    "        image_size=image_size,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    data_t2 = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        img_dirt2,\n",
    "        label_mode='int',\n",
    "        class_names=class_namest2,\n",
    "        batch_size=None,\n",
    "        color_mode='rgb',\n",
    "        image_size=image_size,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "\n",
    "    l_data_t1 = list(data_t1)\n",
    "    l_data_t2 = list(data_t2)\n",
    "\n",
    "\n",
    "    x_pairs = []\n",
    "    y_labels = []\n",
    "\n",
    "    # Generate pairs for the specified category_id\n",
    "    if category_id in rdm_dict:\n",
    "        pairs = rdm_dict[category_id]\n",
    "        for lead, trail in pairs:\n",
    "            # Filter images by label in data_t1 and data_t2 for the current lead and trail categories\n",
    "            lead_images = [img for img, lbl in l_data_t1 if lbl.numpy() == lead]\n",
    "            trail_images = [img for img, lbl in l_data_t2 if lbl.numpy() == trail]\n",
    "\n",
    "            # Generate all possible combinations of image pairs according to current leading and trailing image category\n",
    "            for img_t1, img_t2 in itertools.product(lead_images, trail_images):\n",
    "                # Concatenate images along the height dimension -> (56, 28, 3)\n",
    "                x = tf.concat([img_t1, img_t2], axis=0)  \n",
    "                label = label_dict[(lead, trail)] \n",
    "                y = tf.cast(tf.random.uniform([]) < label, tf.float32) \n",
    "                y = tf.expand_dims(y, axis=0) \n",
    "\n",
    "                x_pairs.append(x)  \n",
    "                y_labels.append(y)  \n",
    "\n",
    "    # Concatenate all pairs and the corresponding labels  \n",
    "    x_stacked = tf.concat([tf.expand_dims(x, axis=0) for x in x_pairs], axis=0)\n",
    "    y_stacked = tf.concat([tf.expand_dims(y, axis=0) for y in y_labels], axis=0)\n",
    "    \n",
    "    return x_stacked, y_stacked  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_with_states(model, x):\n",
    "     outputs = []\n",
    "     for layer in model.layers:\n",
    "          x = layer(x)\n",
    "          outputs.append(x)\n",
    "     return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images from category_id_i: 0\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 0\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 0\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 1\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 0\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 2\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 0\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 3\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 0\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 4\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 0\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 5\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 1\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 0\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 1\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 1\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 1\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 2\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 1\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 3\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 1\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 4\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 1\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 5\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 2\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 0\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 2\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 1\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 2\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 2\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 2\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 3\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 2\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 4\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 2\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 5\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 3\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 0\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 3\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 1\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 3\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 2\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 3\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 3\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 3\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 4\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 3\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 5\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 4\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 0\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 4\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 1\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 4\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 2\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 4\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 3\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 4\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 4\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 4\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 5\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 5\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 0\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 5\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 1\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 5\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 2\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 5\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 3\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_i: 5\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 4\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 18:22:22.135577: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images from category_id_i: 5\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "Processing images from category_id_j: 5\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "################################ Saving all ann-based RDMs now ################################\n"
     ]
    }
   ],
   "source": [
    "rdm_h1_pcn_act = np.zeros((6,6))\n",
    "rdm_h1_pcn_err = np.zeros((6,6))\n",
    "rdm_h1_bp = np.zeros((6,6))\n",
    "\n",
    "rdm_h23_pcn_act_l1 = np.zeros((6,6))\n",
    "rdm_h23_pcn_act_l2 = np.zeros((6,6))\n",
    "\n",
    "\n",
    "category_ids = list(rdm_dict.keys())\n",
    "\n",
    "for i, category_id_i in enumerate(category_ids):\n",
    "    for j, category_id_j in enumerate(category_ids):\n",
    "        \n",
    "            \n",
    "        \n",
    "        # Create category specific image pairs\n",
    "            print(f\"Processing images from category_id_i: {category_id_i}\")\n",
    "            val_dataset_i = generate_possible_img_pairings(\n",
    "                rdm_dict, category_id_i, img_dir_test_lead, img_dir_test_trail, class_names_L, class_names_T, label_dict, image_size=(28, 28), seed=seed\n",
    "            )\n",
    "            \n",
    "            print(f\"Processing images from category_id_j: {category_id_j}\")\n",
    "            val_dataset_j = generate_possible_img_pairings(\n",
    "                rdm_dict, category_id_j, img_dir_test_lead, img_dir_test_trail, class_names_L, class_names_T, label_dict, image_size=(28, 28), seed=seed\n",
    "            )\n",
    "            \n",
    "            # Preprocess and flatten images \n",
    "            val_dataset_i = flatten(*img_preproc(val_dataset_i[0], val_dataset_i[1]))[0] # only return images\n",
    "            val_dataset_j = flatten(*img_preproc(val_dataset_j[0], val_dataset_j[1]))[0]\n",
    "            \n",
    "            # Generate and extract activations \n",
    "            pcn_acts_i, pcn_err_i = pcn.infer(val_dataset_i, return_sequence=True) # shape: (batch_size, n_iter, n_units) \n",
    "            pcn_acts_j, pcn_err_j = pcn.infer(val_dataset_j, return_sequence=True) # shape: (batch_size, n_iter, n_units) \n",
    "            \n",
    "            pcn_acts_i = [tf.reshape(tensor, (tensor.shape[0], -1)) for tensor in pcn_acts_i] # flatten for later concat of all layers in the next step\n",
    "            pcn_acts_j = [tf.reshape(tensor, (tensor.shape[0], -1)) for tensor in pcn_acts_j]\n",
    "            pcn_err_i = [tf.reshape(tensor, (tensor.shape[0], -1)) for tensor in pcn_err_i]\n",
    "            pcn_err_j = [tf.reshape(tensor, (tensor.shape[0], -1)) for tensor in pcn_err_j]\n",
    "            \n",
    "            \n",
    "            bp_acts_i = call_with_states(bp_ann, val_dataset_i)\n",
    "            bp_acts_j = call_with_states(bp_ann, val_dataset_j)\n",
    "\n",
    "         \n",
    "            # RDMs for H1\n",
    "            rdm_h1_pcn_act[i, j] = cosine(np.mean(np.concatenate([layer for layer in pcn_acts_i[1:]], axis=1), axis=0), np.mean(np.concatenate([layer for layer in pcn_acts_j[1:]], axis=1), axis=0)) \n",
    "            rdm_h1_pcn_err[i,j] = cosine(np.mean(np.concatenate([layer for layer in pcn_err_i], axis=1), axis=0), np.mean(np.concatenate([layer for layer in pcn_err_j], axis=1), axis=0)) \n",
    "            rdm_h1_bp[i,j] = cosine(np.mean(np.concatenate([layer for layer in bp_acts_i[1:]], axis=1), axis=0), np.mean(np.concatenate([layer for layer in bp_acts_j[1:]], axis=1), axis=0)) \n",
    "            \n",
    "            # RDMs for H2 & H3\n",
    "            rdm_h23_pcn_act_l1[i,j] = cosine(np.mean(pcn_acts_i[1], axis=0), np.mean(pcn_acts_j[1], axis=0)) \n",
    "            rdm_h23_pcn_act_l2[i,j] = cosine(np.mean(pcn_acts_i[2], axis=0), np.mean(pcn_acts_j[2], axis=0))  \n",
    "             \n",
    "        \n",
    "\n",
    "# Save RDMS\n",
    "print(f\"################################ Saving all ann-based RDMs now ################################\")\n",
    "\n",
    "np.save(os.path.join(results_path_pcn, \"rdm_h1_pcn_act.npy\"), rdm_h1_pcn_act)\n",
    "np.save(os.path.join(results_path_pcn, \"rdm_h1_pcn_error.npy\"), rdm_h1_pcn_err)\n",
    "np.save(os.path.join(results_path_bp, \"rdm_h1_bp.npy\"), rdm_h1_bp)\n",
    "np.save(os.path.join(results_path_pcn, \"rdm_h23_pcn_l1.npy\"), rdm_h23_pcn_act_l1)\n",
    "np.save(os.path.join(results_path_pcn, \"rdm_h23_pcn_l2.npy\"), rdm_h23_pcn_act_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rdm = np.load(\"/Users/denisekittelmann/Documents/Python/BiMoL/results/rdms/ann_RDM/pcn/rdm_h1_pcn_act.npy\")\n",
    "plt.imshow(rdm, cmap='viridis') # twilight_shifted inferno plasma \n",
    "#plt.xticks([])\n",
    "#plt.yticks([])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ PCN NETWORK OBJECT ################################ \n",
    "\n",
    "class CustomDense(tf.keras.layers.Dense):\n",
    "    def call(self, inputs):\n",
    "        \"\"\"This works like a dense, except for the activation being called earlier.\"\"\"\n",
    "        # Apply the activation to the input first\n",
    "        activated_input = self.activation(inputs)\n",
    "        # Perform the matrix multiplication and add the bias\n",
    "        output = tf.matmul(activated_input, self.kernel)\n",
    "        if self.use_bias:\n",
    "            output = output + self.bias\n",
    "        return output\n",
    "\n",
    "\n",
    "class PredictiveCodingNetwork(tf.keras.Sequential):\n",
    "    def __init__(self, layers, vars, beta, **kwargs):\n",
    "        \"\"\"Initialize a PredictiveCodingNetwork\"\"\"\n",
    "        super().__init__(layers, **kwargs)\n",
    "        self.vars = tf.convert_to_tensor(vars, dtype=tf.float32)\n",
    "        self.beta = beta\n",
    "\n",
    "    def call_with_states(self, x):\n",
    "        x_list = [x]\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            x_list.append(x)\n",
    "        return x_list\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        x, y = data\n",
    "\n",
    "        # do the stuff we do in train_epochs\n",
    "        outputs, errors = self.infer(x, y)\n",
    "        self.update_params(outputs, errors)\n",
    "\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        pred = self.call(x)\n",
    "        for metric in self.metrics:\n",
    "            metric.update_state(y, pred)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "   \n",
    "    def infer(self, x_batch, y_batch=None, n_iter=50, return_sequence=False):\n",
    "        \"\"\"Note: while model call, call with states and model evaluate take\n",
    "        2D input, train_step and infer take stacked 3D inputs.\"\"\"\n",
    "        if return_sequence:\n",
    "            errors_time = []\n",
    "            states_time = []\n",
    "        errors = [None for _ in range(len(self.layers))]\n",
    "        f_x_arr = [None for _ in range(len(self.layers))]\n",
    "        f_x_deriv_arr = [None for _ in range(len(self.layers))]\n",
    "        shape = x_batch.shape\n",
    "        batch_size = shape[0]\n",
    "\n",
    "        for itr in range(n_iter):\n",
    "            # if its the first itr, set x to the current forward call\n",
    "            if itr == 0:\n",
    "                x = self.call_with_states(x_batch)\n",
    "\n",
    "                if y_batch is not None:\n",
    "                  x[-1] = y_batch\n",
    "            else:\n",
    "                # update g and x only for consecutive iterations\n",
    "                for l in range(1, len(self.layers)):\n",
    "                    g = tf.multiply(tf.matmul(errors[l], self.layers[l].kernel, transpose_b=True), f_x_deriv_arr[l])\n",
    "                    x[l] = x[l] + self.beta * (-errors[l-1] + g)\n",
    "\n",
    "            # update f_x etc for every iteration\n",
    "            for l in range(len(self.layers)):\n",
    "                f_x = self.layers[l].activation(x[l])\n",
    "                f_x_deriv_fn = self.get_activation_derivative(self.layers[l].activation)\n",
    "                f_x_deriv = f_x_deriv_fn(x[l])\n",
    "                f_x_arr[l] = f_x\n",
    "                f_x_deriv_arr[l] = f_x_deriv\n",
    "                errors[l] = (x[l + 1] - tf.matmul(f_x, self.layers[l].kernel) - self.layers[l].bias) / self.vars[l]\n",
    "            \n",
    "            if return_sequence:\n",
    "                errors_time.append(errors)\n",
    "                states_time.append(x)\n",
    "\n",
    "        # return what we want to return\n",
    "        if return_sequence:\n",
    "            states_time = [tf.stack(tensors, axis=1) for tensors in zip(*states_time)]\n",
    "            errors_time = [tf.stack(tensors, axis=1) for tensors in zip(*errors_time)]\n",
    "            return states_time, errors_time\n",
    "        else:\n",
    "            return x, errors\n",
    "    \n",
    "    # We need to check if we actually need call here.\n",
    "    # Now, call will give us the result of the network after the first inference step\n",
    "    # If we want to have the results after the last inference step, we would need to change this\n",
    "    #def call(self, inputs, training=False):\n",
    "    #    \"\"\"Call, but time distributed.\"\"\"\n",
    "    #    x, errors = self.infer(inputs, return_sequence=False)\n",
    "    #    return x[-1]\n",
    "\n",
    "    def update_params(self, x, errors):\n",
    "        \"\"\"Update the model parameters.\"\"\"\n",
    "        batch_size = tf.cast(tf.shape(x[0])[0], tf.float32)\n",
    "        gradients = []\n",
    "        for l, layer in enumerate(self.layers):\n",
    "            grad_w = self.vars[-1] * (1 / batch_size) * tf.matmul(tf.transpose(self.layers[l].activation(x[l])), errors[l])\n",
    "            grad_b = self.vars[-1] * (1 / batch_size) * tf.reduce_sum(errors[l], axis=0)\n",
    "            gradients.append((-grad_w, layer.kernel))\n",
    "            gradients.append((-grad_b, layer.bias))\n",
    "        self.optimizer.apply_gradients(gradients)\n",
    "\n",
    "    def get_activation_derivative(self, activation):\n",
    "        \"\"\"Return a function for the derivative of the given activation function.\"\"\"\n",
    "        activation_fn = tf.keras.activations.get(activation)\n",
    "        if activation_fn == tf.keras.activations.linear:\n",
    "            return lambda x: tf.ones_like(x)\n",
    "        elif activation_fn == tf.keras.activations.tanh:\n",
    "            return lambda x: 1 - tf.square(tf.nn.tanh(x))\n",
    "        elif activation_fn == tf.keras.activations.sigmoid:\n",
    "            return lambda x: tf.nn.sigmoid(x) * (1 - tf.nn.sigmoid(x))\n",
    "        else:\n",
    "            raise ValueError(f\"{activation} not supported\")\n",
    "        \n",
    "\n",
    "model = PredictiveCodingNetwork([CustomDense(units=6, activation=\"sigmoid\"),\n",
    "                                 CustomDense(units=4, activation=\"sigmoid\"), \n",
    "                                 CustomDense(units=1, activation=\"sigmoid\")], \n",
    "                                vars=[1, 1, 1], # variances. This is super useless and in the code only the last variance is used\n",
    "                                beta=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step\n",
      "Found 180 files belonging to 5 classes.\n",
      "Found 180 files belonging to 4 classes.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820ms/step - accuracy: 0.6722 - loss: 3.9074e-08\n",
      "Test Loss: 3.907416257220575e-08, Test Accuracy: 0.6722221970558167\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Unzip the .keras file to access its internal structure\n",
    "keras_file_path = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/model_checkpoint_pcnoriginal_726_0.67.keras\"\n",
    "unzip_path = \"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/pcn_tt/\"\n",
    "\n",
    "with zipfile.ZipFile(keras_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(unzip_path)\n",
    "\n",
    "# Step 2: Instantiate your custom model with the correct parameters\n",
    "correct_model = model # PCN loaded after reinitialising the network\n",
    "\n",
    "\n",
    "# Now `correct_model` has the loaded weights\n",
    "correct_model.build([None, 4704])\n",
    "correct_model.load_weights(\"/Users/denisekittelmann/Documents/Python/BiMoL/results/pcn/pcn_tt/model.weights.h5\")\n",
    "\n",
    "correct_model.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-7, weight_decay=1e-2),\n",
    "    loss=\"categorical_crossentropy\",  # Placeholder loss\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Predict states\n",
    "predictions = correct_model.predict(val_dataset.batch(512).map(img_preproc).map(flatten))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = correct_model.evaluate(val_dataset.batch(512).map(img_preproc).map(flatten))\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BiMo_3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
